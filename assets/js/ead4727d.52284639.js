"use strict";(globalThis.webpackChunkbook=globalThis.webpackChunkbook||[]).push([[851],{8453:(n,e,i)=>{i.d(e,{R:()=>r,x:()=>s});var t=i(6540);const a={},o=t.createContext(a);function r(n){const e=t.useContext(o);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(a):n.components||a:r(n.components),t.createElement(o.Provider,{value:e},n.children)}},9374:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>l,contentTitle:()=>s,default:()=>m,frontMatter:()=>r,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"part-3-simulation/gazebo-unity-simulation","title":"Gazebo and Unity Simulation","description":"Learning Objectives","source":"@site/docs/part-3-simulation/03-gazebo-unity-simulation.md","sourceDirName":"part-3-simulation","slug":"/part-3-simulation/gazebo-unity-simulation","permalink":"/Ary-s-Physical-Humanoid-Robotics/docs/part-3-simulation/gazebo-unity-simulation","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/part-3-simulation/03-gazebo-unity-simulation.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"title":"Gazebo and Unity Simulation","sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Weeks 3-5 Overview: ROS 2 Fundamentals","permalink":"/Ary-s-Physical-Humanoid-Robotics/docs/part-2-ros2/02a-week-3-5-overview"},"next":{"title":"Weeks 6-7: Simulation Fundamentals","permalink":"/Ary-s-Physical-Humanoid-Robotics/docs/part-3-simulation/03a-week-6-7-overview"}}');var a=i(4848),o=i(8453);const r={title:"Gazebo and Unity Simulation",sidebar_position:3},s="Chapter 3: Gazebo and Unity Simulation",l={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"3.1 Introduction to Robot Simulation",id:"31-introduction-to-robot-simulation",level:2},{value:"Why Simulate?",id:"why-simulate",level:3},{value:"Simulation Fidelity Considerations",id:"simulation-fidelity-considerations",level:3},{value:"The Simulation Development Workflow",id:"the-simulation-development-workflow",level:3},{value:"3.2 Gazebo Simulation Environment Setup",id:"32-gazebo-simulation-environment-setup",level:2},{value:"Installation and Configuration",id:"installation-and-configuration",level:3},{value:"Environment Configuration",id:"environment-configuration",level:3},{value:"3.3 URDF and SDF Robot Description Formats",id:"33-urdf-and-sdf-robot-description-formats",level:2},{value:"Unified Robot Description Format (URDF)",id:"unified-robot-description-format-urdf",level:3},{value:"Simulation Description Format (SDF)",id:"simulation-description-format-sdf",level:3},{value:"3.4 Physics Simulation",id:"34-physics-simulation",level:2},{value:"Joint Types and Configuration",id:"joint-types-and-configuration",level:3},{value:"Contact and Friction Modeling",id:"contact-and-friction-modeling",level:3},{value:"3.5 Sensor Simulation in Gazebo",id:"35-sensor-simulation-in-gazebo",level:2},{value:"Camera Simulation",id:"camera-simulation",level:3},{value:"LIDAR Simulation",id:"lidar-simulation",level:3},{value:"IMU Simulation",id:"imu-simulation",level:3},{value:"Complete Sensor Integration",id:"complete-sensor-integration",level:3},{value:"3.6 Unity for Robot Visualization",id:"36-unity-for-robot-visualization",level:2},{value:"ROS-Unity Integration Architecture",id:"ros-unity-integration-architecture",level:3},{value:"Visualization Best Practices",id:"visualization-best-practices",level:3},{value:"3.7 Simulation Launch and Control",id:"37-simulation-launch-and-control",level:2},{value:"Chapter Summary",id:"chapter-summary",level:2},{value:"Key Concepts",id:"key-concepts",level:3},{value:"Hardware Requirements Reference",id:"hardware-requirements-reference",level:3},{value:"Further Reading",id:"further-reading",level:3},{value:"Next Chapter",id:"next-chapter",level:3}];function d(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,o.R)(),...n.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.header,{children:(0,a.jsx)(e.h1,{id:"chapter-3-gazebo-and-unity-simulation",children:"Chapter 3: Gazebo and Unity Simulation"})}),"\n",(0,a.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,a.jsx)(e.p,{children:"By the end of this chapter, you will be able to:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Understand the importance of robot simulation in development workflows"}),"\n",(0,a.jsx)(e.li,{children:"Configure Gazebo simulation environments for humanoid robot testing"}),"\n",(0,a.jsx)(e.li,{children:"Create URDF and SDF descriptions for robot models with sensors"}),"\n",(0,a.jsx)(e.li,{children:"Configure physics simulation including joints, constraints, and collision properties"}),"\n",(0,a.jsx)(e.li,{children:"Implement sensor simulation for cameras, LIDAR, and IMUs"}),"\n",(0,a.jsx)(e.li,{children:"Use Unity for high-fidelity robot visualization and rendering"}),"\n",(0,a.jsx)(e.li,{children:"Integrate simulation with ROS 2 for complete development workflows"}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"31-introduction-to-robot-simulation",children:"3.1 Introduction to Robot Simulation"}),"\n",(0,a.jsx)(e.p,{children:"Robot simulation has become an indispensable tool in the development of humanoid robotics. Before diving into the technical aspects of simulation setup and configuration, it is essential to understand why simulation matters and how it fits into the overall development workflow for physical humanoid robots."}),"\n",(0,a.jsx)(e.h3,{id:"why-simulate",children:"Why Simulate?"}),"\n",(0,a.jsx)(e.p,{children:"The development of humanoid robots involves significant risks and costs that simulation helps mitigate. Physical testing on real hardware can result in equipment damage, personal injury, and substantial downtime while repairs are made. A humanoid robot with 30+ degrees of freedom, sophisticated sensors, and complex control systems represents a significant financial investment, often costing hundreds of thousands of dollars. Simulation allows developers to test algorithms, validate control strategies, and iterate on designs without risking this expensive hardware."}),"\n",(0,a.jsx)(e.p,{children:"Beyond risk mitigation, simulation enables development scenarios that would be impractical or impossible with physical robots. Testing robot behavior in hazardous environments, extreme temperatures, or space conditions requires simulation. Reproducing edge cases and failure modes for validation and certification becomes straightforward in simulation. Researchers can explore robot learning through reinforcement learning, testing millions of iterations that would take years on physical hardware."}),"\n",(0,a.jsx)(e.p,{children:"Simulation also democratizes robot development by reducing the physical infrastructure requirements. Teams without access to well-equipped robotics laboratories can still develop and test algorithms. This accessibility accelerates innovation and allows more researchers and developers to contribute to the field."}),"\n",(0,a.jsx)(e.h3,{id:"simulation-fidelity-considerations",children:"Simulation Fidelity Considerations"}),"\n",(0,a.jsx)(e.p,{children:"Not all simulations are created equal, and choosing the appropriate level of fidelity depends on the development stage and objectives. Low-fidelity simulation prioritizes speed and scalability, suitable for algorithm development, integration testing, and rapid prototyping. High-fidelity simulation focuses on physical accuracy, sensor realism, and environmental detail, essential for final validation, perception algorithm development, and hardware-in-the-loop testing."}),"\n",(0,a.jsx)(e.p,{children:"Gazebo strikes an effective balance between fidelity and performance, offering configurable physics engines, realistic sensor models, and efficient computation. For humanoid robotics, Gazebo has become the standard simulation environment due to its ROS integration, extensive sensor model library, and active community support. Unity complements Gazebo by providing superior rendering capabilities for visualization, marketing materials, and human-robot interaction studies."}),"\n",(0,a.jsx)(e.h3,{id:"the-simulation-development-workflow",children:"The Simulation Development Workflow"}),"\n",(0,a.jsx)(e.p,{children:"Effective simulation integration follows a staged approach that aligns with hardware readiness and development maturity. In the early stages, when algorithms are being developed and concepts validated, simulation provides the primary development environment. Hardware-in-the-loop testing begins once basic functionality is verified, using simulation alongside physical robot testing. As development matures, simulation serves increasingly for regression testing, edge case validation, and continuous integration."}),"\n",(0,a.jsx)(e.p,{children:"This workflow requires maintaining consistency between simulation and physical robot implementations. Changes to sensor configurations, actuator characteristics, or physical parameters must propagate to both environments. Establishing clear interfaces and version control practices prevents drift between simulated and physical systems."}),"\n",(0,a.jsx)(e.h2,{id:"32-gazebo-simulation-environment-setup",children:"3.2 Gazebo Simulation Environment Setup"}),"\n",(0,a.jsx)(e.p,{children:"Gazebo's architecture separates the simulation server from visualization clients, allowing multiple users to observe and interact with the same simulation instance. Understanding this architecture helps in configuring efficient development environments and troubleshooting issues."}),"\n",(0,a.jsx)(e.h3,{id:"installation-and-configuration",children:"Installation and Configuration"}),"\n",(0,a.jsx)(e.p,{children:"Gazebo installation on Ubuntu 22.04 follows a straightforward process through the osrfoundation repository:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-bash",children:"# Add Gazebo repository\nsudo apt-get update\nsudo apt-get install gnupg\nsudo wget https://packages.osrfoundation.org/gazebo/keys/packages.key -O - | sudo apt-key add -\nsudo sh -c 'echo \"deb http://packages.osrfoundation.org/gazebo/ubuntu-stable $(lsb_release -cs) main\" > /etc/apt/sources.list.d/gazebo-stable.list'\n\n# Install Gazebo Harmonic (current recommended version)\nsudo apt-get update\nsudo apt-get install gz-harmonic ros-humble-gazebo-ros-pkgs\n\n# Verify installation\ngz sim --version\n"})}),"\n",(0,a.jsx)(e.p,{children:"The simulation requires careful resource allocation for smooth operation with humanoid models. The physics simulation step size, typically 1 millisecond for accurate dynamics, determines computational requirements. A simulation step requires calculating positions, velocities, and accelerations for all joints, resolving contacts, and updating sensor readings. Humanoid robots with 30+ joints, multiple contact points, and several sensors can strain single-core computation."}),"\n",(0,a.jsx)(e.p,{children:"For complex humanoid simulations, consider configuring multi-threaded physics or distributed simulation. Gazebo supports running physics in a separate thread from rendering, reducing visualization impact on simulation accuracy. The following configuration demonstrates thread separation and resource allocation:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-xml",children:'\x3c!-- ~/.gz/sim/config/humanoid_simulation.config --\x3e\n<sdf version="1.10">\n  <world name="humanoid_world">\n    <physics name="multi-threaded-physics" default="true" type="omp">\n      <engine name="dart">\n        <max_step_size>0.001</max_step_size>\n        <real_time_factor>1.0</real_time_factor>\n        <real_time_update_rate>1000</real_time_update_rate>\n        <num_threads>4</num_threads>\n      </engine>\n    </physics>\n    <gui>\n      <camera name="main_camera">\n        <pose>2.0 2.0 1.5 0 0.3 2.5</pose>\n      </camera>\n    </gui>\n  </world>\n</sdf>\n'})}),"\n",(0,a.jsx)(e.h3,{id:"environment-configuration",children:"Environment Configuration"}),"\n",(0,a.jsx)(e.p,{children:"Creating appropriate simulation environments involves configuring gravity, lighting, ground plane, and atmospheric conditions. Humanoid robots require careful ground contact modeling, as walking dynamics depend critically on friction and contact resolution."}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-xml",children:'\x3c!-- humanoid_world.sdf --\x3e\n<?xml version="1.0" ?>\n<sdf version="1.10">\n  <world name="humanoid_simulation">\n    \x3c!-- Physics configuration for stable walking simulation --\x3e\n    <physics name="dart" type="dart">\n      <max_step_size>0.001</max_step_size>\n      <real_time_factor>1.0</real_time_factor>\n      <real_time_update_rate>1000</real_time_update_rate>\n      <gravity>0 0 -9.81</gravity>\n      <dart name="dart">\n        <solver>\n          <type>dantzig</type>\n          <dtosolver_iterations>30</dtosolver_iterations>\n          <sor_iterations>50</sor_iterations>\n          <use_adaptive_time_stepping>true</use_adaptive_time_stepping>\n        </solver>\n      </dart>\n    </physics>\n\n    \x3c!-- Ground plane with friction configuration for walking --\x3e\n    <model name="ground_plane">\n      <pose>0 0 0 0 0 0</pose>\n      <link name="ground">\n        <collision name="ground_collision">\n          <geometry>\n            <plane>\n              <size>20 20</size>\n            </plane>\n          </geometry>\n          <surface>\n            <friction>\n              <ode>\n                <mu>0.8</mu>\n                <mu2>0.8</mu2>\n                <fdir1>0 0 1</fdir1>\n                <slip1>0.0</slip1>\n                <slip2>0.0</slip2>\n              </ode>\n            </friction>\n            <contact>\n              <collide_without_contact>0</collide_without_contact>\n              <collide_without_contact_bitmask>1</collide_without_contact_bitmask>\n              <collide_bitmask>1</collide_bitmask>\n              <contact_cfm>0.0</contact_cfm>\n              <contact_erp>0.2</contact_erp>\n            </contact>\n          </surface>\n        </collision>\n        <visual name="ground_visual">\n          <geometry>\n            <plane>\n              <size>20 20</size>\n            </plane>\n          </geometry>\n          <material>\n            <script>\n              <uri>file://media/materials/scripts/gazebo.material</uri>\n              <name>Gazebo/Gray</name>\n            <\/script>\n          </material>\n        </visual>\n      </link>\n    </model>\n\n    \x3c!-- Lighting configuration for perception testing --\x3e\n    <light name="sun" type="directional">\n      <pose>5 5 10 0 0.5 0</pose>\n      <diffuse>0.8 0.8 0.8 1</diffuse>\n      <specular>0.2 0.2 0.2 1</specular>\n      <cast_shadows>true</cast_shadows>\n      <intensity>1.0</intensity>\n      <direction>0.1 -0.1 -1</direction>\n    </light>\n\n    \x3c!-- Include sensor models from Gazebo model database --\x3e\n    <include>\n      <uri>model://camera</uri>\n      <name>head_camera</uri>\n    </include>\n  </world>\n</sdf>\n'})}),"\n",(0,a.jsx)(e.h2,{id:"33-urdf-and-sdf-robot-description-formats",children:"3.3 URDF and SDF Robot Description Formats"}),"\n",(0,a.jsx)(e.p,{children:"Robot description formats provide the mathematical representation of robot structure for simulation, visualization, and motion planning. Understanding both URDF and SDF, their strengths, and appropriate use cases is essential for humanoid robot development."}),"\n",(0,a.jsx)(e.h3,{id:"unified-robot-description-format-urdf",children:"Unified Robot Description Format (URDF)"}),"\n",(0,a.jsx)(e.p,{children:"URDF uses XML to describe robot kinematics and visual properties. The format organizes robots as a tree of links connected by joints, where links represent rigid bodies and joints represent connections allowing relative motion."}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-xml",children:'\x3c!-- humanoid.urdf.xacro --\x3e\n<?xml version="1.0" ?>\n<robot name="atlas_humanoid" xmlns:xacro="http://wiki.ros.org/xacro">\n  \x3c!-- Include macros and constants --\x3e\n  <xacro:include filename="$(find humanoid_description)/urdf/constants.urdf.xacro" />\n  <xacro:include filename="$(find humanoid_description)/urdf/materials.urdf.xacro" />\n\n  \x3c!-- Base link - world connection --\x3e\n  <link name="base_link">\n    <inertial>\n      <mass value="${base_mass}" />\n      <origin xyz="0 0 0" rpy="0 0 0" />\n      <inertia ixx="${base_ixx}" ixy="${base_ixy}" ixz="${base_ixz}"\n               iyy="${base_iyy}" iyz="${base_iyz}" izz="${base_izz}" />\n    </inertial>\n    <visual>\n      <origin xyz="0 0 0" rpy="0 0 0" />\n      <geometry>\n        <box size="${base_width} ${base_depth} ${base_height}" />\n      </geometry>\n      <material name="base_color" />\n    </visual>\n    <collision>\n      <origin xyz="0 0 0" rpy="0 0 0" />\n      <geometry>\n        <box size="${base_width} ${base_depth} ${base_height}" />\n      </geometry>\n    </collision>\n  </link>\n\n  \x3c!-- Pelvis link - central body reference --\x3e\n  <link name="pelvis_link">\n    <inertial>\n      <mass value="${pelvis_mass}" />\n      <origin xyz="0 0 ${pelvis_z_offset}" rpy="0 0 0" />\n      <inertia ixx="${pelvis_ixx}" ixy="0" ixz="0"\n               iyy="${pelvis_iyy}" iyz="0" izz="${pelvis_izz}" />\n    </inertial>\n    <visual>\n      <origin xyz="0 0 ${pelvis_z_offset}" rpy="0 0 0" />\n      <geometry>\n        <cylinder radius="${pelvis_radius}" length="${pelvis_length}" />\n      </geometry>\n      <material name="pelvis_color" />\n    </visual>\n    <collision>\n      <origin xyz="0 0 ${pelvis_z_offset}" rpy="0 0 0" />\n      <geometry>\n        <cylinder radius="${pelvis_radius}" length="${pelvis_length}" />\n      </geometry>\n    </collision>\n  </link>\n\n  \x3c!-- Continuous joint for yaw rotation --\x3e\n  <joint name="base_to_pelvis" type="fixed">\n    <origin xyz="0 0 ${pelvis_height}" rpy="0 0 0" />\n    <parent link="base_link" />\n    <child link="pelvis_link" />\n    <axis xyz="0 0 1" />\n  </joint>\n\n  \x3c!-- Left hip yaw joint --\x3e\n  <joint name="left_hip_yaw" type="revolute">\n    <origin xyz="0 ${hip_separation/2} 0" rpy="0 0 0" />\n    <parent link="pelvis_link" />\n    <child link="left_hip_link" />\n    <axis xyz="0 0 1" />\n    <limit lower="-1.57" upper="1.57" effort="150" velocity="5.0" />\n    <dynamics damping="0.5" friction="2.0" />\n  </joint>\n\n  \x3c!-- Left hip link --\x3e\n  <link name="left_hip_link">\n    <inertial>\n      <mass value="2.5" />\n      <origin xyz="0 0.05 -0.1" rpy="0 0 0" />\n      <inertia ixx="0.01" ixy="0" ixz="0"\n               iyy="0.02" iyz="0.001" izz="0.01" />\n    </inertial>\n    <visual>\n      <geometry>\n        <box size="0.15 0.12 0.25" />\n      </geometry>\n      <material name="hip_color" />\n    </visual>\n    <collision>\n      <geometry>\n        <box size="0.15 0.12 0.25" />\n      </geometry>\n    </collision>\n  </link>\n\n  \x3c!-- Left hip roll joint --\x3e\n  <joint name="left_hip_roll" type="revolute">\n    <origin xyz="0 0 -0.15" rpy="0 0 0" />\n    <parent link="left_hip_link" />\n    <child link="left_upper_leg_link" />\n    <axis xyz="1 0 0" />\n    <limit lower="-0.5" upper="0.5" effort="150" velocity="5.0" />\n    <dynamics damping="0.5" friction="2.0" />\n  </joint>\n\n  \x3c!-- Left upper leg link --\x3e\n  <link name="left_upper_leg_link">\n    <inertial>\n      <mass value="5.0" />\n      <origin xyz="0 0 -0.25" rpy="0 0 0" />\n      <inertia ixx="0.05" ixy="0" ixz="0"\n               iyy="0.02" iyz="0" izz="0.05" />\n    </inertial>\n    <visual>\n      <geometry>\n        <cylinder radius="0.08" length="0.50" />\n      </geometry>\n      <material name="leg_color" />\n    </visual>\n    <collision>\n      <geometry>\n        <cylinder radius="0.08" length="0.50" />\n      </geometry>\n    </collision>\n  </link>\n\n  \x3c!-- Left knee joint --\x3e\n  <joint name="left_knee" type="revolute">\n    <origin xyz="0 0 -0.50" rpy="0 0 0" />\n    <parent link="left_upper_leg_link" />\n    <child link="left_lower_leg_link" />\n    <axis xyz="1 0 0" />\n    <limit lower="-2.0" upper="0" effort="100" velocity="8.0" />\n    <dynamics damping="0.3" friction="1.5" />\n  </joint>\n\n  \x3c!-- Left lower leg link --\x3e\n  <link name="left_lower_leg_link">\n    <inertial>\n      <mass value="3.0" />\n      <origin xyz="0 0 -0.25" rpy="0 0 0" />\n      <inertia ixx="0.03" ixy="0" ixz="0"\n               iyy="0.01" iyz="0" izz="0.03" />\n    </inertial>\n    <visual>\n      <geometry>\n        <cylinder radius="0.06" length="0.50" />\n      </geometry>\n      <material name="leg_color" />\n    </visual>\n    <collision>\n      <geometry>\n        <cylinder radius="0.06" length="0.50" />\n      </geometry>\n    </collision>\n  </link>\n\n  \x3c!-- Left ankle joint --\x3e\n  <joint name="left_ankle" type="revolute">\n    <origin xyz="0 0 -0.50" rpy="0 0 0" />\n    <parent link="left_lower_leg_link" />\n    <child link="left_foot_link" />\n    <axis xyz="1 0 0" />\n    <limit lower="-0.5" upper="0.5" effort="80" velocity="6.0" />\n    <dynamics damping="0.3" friction="1.5" />\n  </joint>\n\n  \x3c!-- Left foot link --\x3e\n  <link name="left_foot_link">\n    <inertial>\n      <mass value="1.5" />\n      <origin xyz="0.05 0 -0.02" rpy="0 0 0" />\n      <inertia ixx="0.01" ixy="0" ixz="0"\n               iyy="0.02" iyz="0" izz="0.01" />\n    </inertial>\n    <visual>\n      <origin xyz="0.05 0 -0.02" rpy="0 0 0" />\n      <geometry>\n        <box size="0.25 0.12 0.04" />\n      </geometry>\n      <material name="foot_color" />\n    </visual>\n    <collision>\n      <origin xyz="0.05 0 -0.02" rpy="0 0 0" />\n      <geometry>\n        <box size="0.25 0.12 0.04" />\n      </geometry>\n    </collision>\n  </link>\n\n  \x3c!-- Right leg mirrors left leg --\x3e\n  <joint name="right_hip_yaw" type="revolute">\n    <origin xyz="0 ${-hip_separation/2} 0" rpy="0 0 0" />\n    <parent link="pelvis_link" />\n    <child link="right_hip_link" />\n    <axis xyz="0 0 1" />\n    <limit lower="-1.57" upper="1.57" effort="150" velocity="5.0" />\n    <dynamics damping="0.5" friction="2.0" />\n  </joint>\n\n  \x3c!-- Left shoulder joint --\x3e\n  <joint name="left_shoulder_pitch" type="revolute">\n    <origin xyz="0 ${shoulder_x_offset} ${shoulder_z_offset}" rpy="0 0 0" />\n    <parent link="torso_link" />\n    <child link="left_upper_arm_link" />\n    <axis xyz="1 0 0" />\n    <limit lower="-3.14" upper="3.14" effort="80" velocity="6.0" />\n    <dynamics damping="0.3" friction="1.0" />\n  </joint>\n\n  \x3c!-- IMU sensor link --\x3e\n  <link name="imu_link">\n    <inertial>\n      <mass value="0.05" />\n      <origin xyz="0 0 0" rpy="0 0 0" />\n      <inertia ixx="1e-5" ixy="0" ixz="0"\n               iyy="1e-5" iyz="0" izz="1e-5" />\n    </inertial>\n  </link>\n\n  \x3c!-- IMU joint to pelvis --\x3e\n  <joint name="imu_joint" type="fixed">\n    <origin xyz="0 0 ${torso_height/2}" rpy="0 0 0" />\n    <parent link="torso_link" />\n    <child link="imu_link" />\n    <axis xyz="0 0 1" />\n  </joint>\n\n  \x3c!-- Head link --\x3e\n  <link name="head_link">\n    <inertial>\n      <mass value="1.0" />\n      <origin xyz="0 0 0.15" rpy="0 0 0" />\n      <inertia ixx="0.01" ixy="0" ixz="0"\n               iyy="0.01" iyz="0" izz="0.01" />\n    </inertial>\n    <visual>\n      <origin xyz="0 0 0.15" rpy="0 0 0" />\n      <geometry>\n        <sphere radius="0.12" />\n      </geometry>\n      <material name="head_color" />\n    </visual>\n    <collision>\n      <origin xyz="0 0 0.15" rpy="0 0 0" />\n      <geometry>\n        <sphere radius="0.12" />\n      </geometry>\n    </collision>\n  </link>\n\n  \x3c!-- Head joint --\x3e\n  <joint name="neck_joint" type="revolute">\n    <origin xyz="0 0 ${torso_height/2}" rpy="0 0 0" />\n    <parent link="torso_link" />\n    <child link="head_link" />\n    <axis xyz="0 1 0" />\n    <limit lower="-1.0" upper="1.0" effort="20" velocity="3.0" />\n    <dynamics damping="0.2" friction="0.5" />\n  </joint>\n\n  \x3c!-- Transmissions for hardware interfaces --\x3e\n  <transmission name="left_hip_yaw_trans">\n    <type>transmission_interface/SimpleTransmission</type>\n    <joint name="left_hip_yaw">\n      <hardwareInterface>hardware_interface/EffortJointInterface</hardwareInterface>\n    </joint>\n    <actuator name="left_hip_yaw_motor">\n      <mechanicalReduction>1.0</mechanicalReduction>\n    </actuator>\n  </transmission>\n\n  <transmission name="left_knee_trans">\n    <type>transmission_interface/SimpleTransmission</type>\n    <joint name="left_knee">\n      <hardwareInterface>hardware_interface/EffortJointInterface</hardwareInterface>\n    </joint>\n    <actuator name="left_knee_motor">\n      <mechanicalReduction>1.0</mechanicalReduction>\n    </actuator>\n  </transmission>\n</robot>\n'})}),"\n",(0,a.jsx)(e.h3,{id:"simulation-description-format-sdf",children:"Simulation Description Format (SDF)"}),"\n",(0,a.jsx)(e.p,{children:"SDF provides more comprehensive modeling capabilities than URDF, supporting nested models, scenes, plugins, and advanced physics. SDF is Gazebo's native format and should be used for complex simulation scenarios."}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-xml",children:'\x3c!-- humanoid_complete.sdf --\x3e\n<?xml version="1.0" ?>\n<sdf version="1.10">\n  <world name="humanoid_simulation">\n    <plugin name="ros2_interface" filename="libgazebo_ros2_control.so">\n      <parameters>$(find humanoid_control)/config/controllers.yaml</parameters>\n    </plugin>\n\n    <model name="atlas_humanoid">\n      <pose>0 0 1.0 0 0 0</pose>\n\n      \x3c!-- Joint state publisher plugin --\x3e\n      <plugin name="joint_state_publisher" filename="libgazebo_ros_joint_state_publisher.so">\n        <ros>\n          <namespace>/humanoid</namespace>\n          <remapping>joint_states:=joint_states</remapping>\n        </ros>\n        <publish_rate>100</publish_rate>\n      </plugin>\n\n      \x3c!-- Link definitions with full inertial, visual, and collision --\x3e\n      <link name="pelvis">\n        <pose>0 0 0.95 0 0 0</pose>\n        <inertial>\n          <mass>15.0</mass>\n          <pose>0 0 0 0 0 0</pose>\n          <inertia>\n            <ixx>0.5</ixx>\n            <ixy>0</ixy>\n            <ixz>0</ixz>\n            <iyy>0.3</iyy>\n            <iyz>0</iyz>\n            <izz>0.5</izz>\n          </inertia>\n        </inertial>\n        <visual name="pelvis_visual">\n          <geometry>\n            <cylinder>\n              <radius>0.15</radius>\n              <length>0.1</length>\n            </cylinder>\n          </geometry>\n          <material>\n            <script>\n              <uri>file://media/materials/scripts/gazebo.material</uri>\n              <name>Gazebo/Blue</name>\n            <\/script>\n          </material>\n        </visual>\n        <collision name="pelvis_collision">\n          <geometry>\n            <cylinder>\n              <radius>0.15</radius>\n              <length>0.1</length>\n            </cylinder>\n          </geometry>\n          <surface>\n            <friction>\n              <ode>\n                <mu>0.8</mu>\n                <mu2>0.8</mu2>\n              </ode>\n            </friction>\n          </surface>\n        </collision>\n      </link>\n\n      \x3c!-- Left leg with full joint chain --\x3e\n      <link name="left_hip">\n        <pose>0 0.12 0 0 0 0</pose>\n        <inertial>\n          <mass>5.0</mass>\n          <inertia>\n            <ixx>0.1</ixx>\n            <iyy>0.05</iyy>\n            <izz>0.1</izz>\n          </inertia>\n        </inertial>\n        <visual name="left_hip_visual">\n          <geometry>\n            <box size="0.1 0.08 0.15</size>\n          </geometry>\n          <material>\n            <script>\n              <uri>file://media/materials/scripts/gazebo.material</uri>\n              <name>Gazebo/DarkGray</name>\n            <\/script>\n          </material>\n        </visual>\n      </link>\n\n      <joint name="left_hip_yaw" type="revolute">\n        <parent>pelvis</parent>\n        <child>left_hip</child>\n        <pose>0 0.12 0 0 0 0</pose>\n        <axis>\n          <xyz>0 0 1</xyz>\n        </axis>\n        <limit>\n          <lower>-1.57</lower>\n          <upper>1.57</upper>\n          <effort>150</effort>\n          <velocity>5.0</velocity>\n        </limit>\n        <physics>\n          <ode>\n            <cfm>0.0</cfm>\n            <erp>0.2</erp>\n          </ode>\n        </physics>\n      </joint>\n\n      \x3c!-- Sensor plugins for the humanoid --\x3e\n      <link name="head_camera_link">\n        <pose>0 0 0.25 0 -0.3 0</pose>\n        <plugin name="camera_plugin" filename="libgazebo_ros_camera.so">\n          <ros>\n            <namespace>/humanoid</namespace>\n            <remapping>image_raw:=camera/image_raw</remapping>\n            <remapping>camera_info:=camera/camera_info</remapping>\n          </ros>\n          <camera_name>head_camera</camera_name>\n          <frame_name>head_camera_link</frame_name>\n          <hack_baseline>0.07</hack_baseline>\n        </plugin>\n      </link>\n\n      \x3c!-- IMU sensor on pelvis --\x3e\n      <link name="imu_link">\n        <pose>0 0 0.02 0 0 0</pose>\n        <plugin name="imu_plugin" filename="libgazebo_ros_imu.so">\n          <ros>\n            <namespace>/humanoid</namespace>\n            <remapping>imu:=imu/data</remapping>\n          </ros>\n          <frame_name>imu_link</frame_name>\n          <topic_name>/humanoid/imu/data</topic_name>\n        </plugin>\n      </link>\n\n      \x3c!-- Force/torque sensors at feet --\x3e\n      <link name="left_foot_link">\n        <pose>0.05 0 -0.45 0 0 0</pose>\n        <plugin name="ft_sensor" filename="libgazebo_ros_force_torque.so">\n          <ros>\n            <namespace>/humanoid</namespace>\n            <remapping>force_torque:=left_foot/ft</remapping>\n          </ros>\n          <frame_name>left_foot_link</frame_name>\n          <measure_direction>child_to_parent</measure_direction>\n        </plugin>\n      </link>\n    </model>\n\n    \x3c!-- Environment elements --\x3e\n    <model name="obstacle_course">\n      <pose>2.0 0 0 0 0 0</pose>\n      <link name="box1">\n        <pose>0 0 0.25 0 0 0</pose>\n        <visual name="box1_visual">\n          <geometry>\n            <box size="0.5 0.5 0.5</size>\n          </geometry>\n        </visual>\n        <collision name="box1_collision">\n          <geometry>\n            <box size="0.5 0.5 0.5</size>\n          </geometry>\n        </collision>\n      </link>\n    </model>\n  </world>\n</sdf>\n'})}),"\n",(0,a.jsx)(e.h2,{id:"34-physics-simulation",children:"3.4 Physics Simulation"}),"\n",(0,a.jsx)(e.p,{children:"Accurate physics simulation is fundamental to meaningful humanoid robot testing. This section covers joint dynamics, contact modeling, and constraint configuration for realistic simulation behavior."}),"\n",(0,a.jsx)(e.h3,{id:"joint-types-and-configuration",children:"Joint Types and Configuration"}),"\n",(0,a.jsx)(e.p,{children:"Humanoid robots require various joint types to achieve their range of motion. Revolute joints provide single-axis rotation common in biological joints. Continuous joints allow unlimited rotation for neck and waist yaw. Prismatic joints enable linear motion for suspension systems. Fixed joints rigidly connect links that should not move relative to each other."}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-yaml",children:"# joint_config.yaml\n# Joint configuration for humanoid robot simulation\n# Reference: See Appendix B for physics engine configuration details\n\njoints:\n  # Lower body joints - high power for walking\n  left_hip_yaw:\n    type: revolute\n    axis: [0, 0, 1]\n    position:\n      min: -1.57  # -90 degrees\n      max: 1.57   # +90 degrees\n    limits:\n      effort: 150.0  # Nm\n      velocity: 5.0   # rad/s\n    dynamics:\n      damping: 0.5    # Linear damping coefficient\n      friction: 2.0   # Coulomb friction\n    safety:\n      k_position: 100.0\n      k_velocity: 2.0\n\n  left_hip_roll:\n    type: revolute\n    axis: [1, 0, 0]\n    position:\n      min: -0.5\n      max: 0.5\n    limits:\n      effort: 150.0\n      velocity: 5.0\n    dynamics:\n      damping: 0.5\n      friction: 2.0\n\n  left_knee:\n    type: revolute\n    axis: [1, 0, 0]\n    position:\n      min: -2.0  # Nearly straight to bent\n      max: 0.0\n    limits:\n      effort: 100.0\n      velocity: 8.0\n    dynamics:\n      damping: 0.3\n      friction: 1.5\n    # Stiffness for series elastic actuation\n    stiffness: 500.0\n    damping_isa: 10.0\n\n  left_ankle_pitch:\n    type: revolute\n    axis: [1, 0, 0]\n    position:\n      min: -0.5\n      max: 0.5\n    limits:\n      effort: 80.0\n      velocity: 6.0\n    dynamics:\n      damping: 0.3\n      friction: 1.5\n\n  # Upper body joints - lower power but precision\n  left_shoulder_pitch:\n    type: revolute\n    axis: [1, 0, 0]\n    position:\n      min: -3.14\n      max: 3.14\n    limits:\n      effort: 80.0\n      velocity: 6.0\n    dynamics:\n      damping: 0.3\n      friction: 1.0\n\n  left_elbow:\n    type: revolute\n    axis: [1, 0, 0]\n    position:\n      min: -2.5\n      max: 0.0\n    limits:\n      effort: 50.0\n      velocity: 8.0\n    dynamics:\n      damping: 0.2\n      friction: 0.8\n\n  neck_yaw:\n    type: revolute\n    axis: [0, 1, 0]\n    position:\n      min: -1.0\n      max: 1.0\n    limits:\n      effort: 20.0\n      velocity: 3.0\n    dynamics:\n      damping: 0.2\n      friction: 0.5\n\n# Contact parameters for foot-ground interaction\ncontact:\n  foot:\n    material: rubber\n    friction:\n      mu: 0.8        # Coefficient of friction\n      mu2: 0.8       # Secondary friction direction\n      slip1: 0.0     # Velocity-dependent slip\n      slip2: 0.0\n    contact:\n      cfm: 0.0       # Constraint force mixing\n      erp: 0.2       # Error reduction parameter\n      max_contact_cfm: 1e-5\n      max_contact_erp: 0.1\n    bounce:\n      restitution: 0.0  # No bouncing for walking\n      threshold: 100.0\n\n# ODE physics solver settings\nphysics:\n  solver:\n    type: dantzig  # Fast LCP solver\n    iterations: 30    # LCP solver iterations\n    sor: 1.0         # Successive over-relaxation\n  contacts:\n    max_contacts: 20  # Maximum contact points\n    max_contacts_per_link: 5\n"})}),"\n",(0,a.jsx)(e.h3,{id:"contact-and-friction-modeling",children:"Contact and Friction Modeling"}),"\n",(0,a.jsx)(e.p,{children:"Realistic foot-ground interaction requires careful contact parameter tuning. The friction model determines whether the robot can walk without slipping, while restitution controls bounce behavior. For indoor environments, moderate friction with no restitution provides stable walking behavior."}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-xml",children:'\x3c!-- contact_parameters.sdf --\x3e\n<sdf version="1.10">\n  <world name="humanoid_simulation">\n    <physics name="physics" type="dart">\n      <dart>\n        <collision_detector>bullet</collision_detector>\n        <solver>\n          <type>dantzig</type>\n          <dtosolver_iterations>30</dtosolver_iterations>\n          <sor_iterations>50</sor_iterations>\n          <use_adaptive_time_stepping>true</use_adaptive_time_stepping>\n        </solver>\n      </dart>\n    </physics>\n\n    \x3c!-- Custom friction model for humanoid walking --\x3e\n    <model name="custom_friction_floor">\n      <link name="floor">\n        <collision name="collision">\n          <geometry>\n            <plane>\n              <size>50 50</size>\n            </plane>\n          </geometry>\n          <surface>\n            <friction>\n              <ode>\n                <mu>0.9</mu>\n                <mu2>0.9</mu2>\n                <fdir1>1 0 0</fdir1>\n                <slip1>0.01</slip1>\n                <slip2>0.01</slip2>\n              </ode>\n              <torsional>\n                <coefficient>0.1</coefficient>\n                <patch_radius>0.1</patch_radius>\n              </torsional>\n            </friction>\n            <bounce>\n              <restitution_coefficient>0.0</restitution_coefficient>\n              <threshold_velocity>0.5</threshold_velocity>\n            </bounce>\n            <contact>\n              <collide_without_contact>0</collide_without_contact>\n              <collide_without_contact_bitmask>1</collide_without_contact_bitmask>\n              <collide_bitmask>1</collide_bitmask>\n              <contact_cfm>0.0</contact_cfm>\n              <contact_erp>0.2</contact_erp>\n            </contact>\n          </surface>\n        </collision>\n      </link>\n    </model>\n  </world>\n</sdf>\n'})}),"\n",(0,a.jsx)(e.h2,{id:"35-sensor-simulation-in-gazebo",children:"3.5 Sensor Simulation in Gazebo"}),"\n",(0,a.jsx)(e.p,{children:"Simulated sensors must produce data similar to physical sensors for algorithm development. This section covers camera, LIDAR, and IMU simulation with realistic noise models and configurations."}),"\n",(0,a.jsx)(e.h3,{id:"camera-simulation",children:"Camera Simulation"}),"\n",(0,a.jsx)(e.p,{children:"Camera simulation includes lens distortion, exposure effects, and noise modeling. For humanoid applications, head-mounted cameras require proper pose tracking and synchronization with robot motion."}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-xml",children:'\x3c!-- camera_sensor.sdf --\x3e\n<sdf version="1.10">\n  <model name="head_camera">\n    <link name="camera_link">\n      <pose>0 0 0 0 -0.3 0</pose>\n\n      \x3c!-- Camera sensor plugin --\x3e\n      <plugin name="camera_plugin" filename="libgazebo_ros_camera.so">\n        <ros>\n          <namespace>/humanoid</namespace>\n          <remapping>image_raw:=camera/image_raw</remapping>\n          <remapping>camera_info:=camera/camera_info</remapping>\n          <remapping>depth_image:=camera/depth_image</remapping>\n        </ros>\n\n        \x3c!-- Camera parameters matching physical sensor --\x3e\n        <camera_name>head_camera</camera_name>\n        <frame_name>camera_link</frame_name>\n\n        \x3c!-- Image properties --\x3e\n        <image>\n          <width>1280</width>\n          <height>720</height>\n          <format>R8G8B8</format>\n        </image>\n\n        \x3c!-- Clip planes --\x3e\n        <clip>\n          <near>0.1</near>\n          <far>100.0</far>\n        </clip>\n\n        \x3c!-- Lens distortion (Brown-Conrady model) --\x3e\n        <distortion>\n          <k1>-0.2</k1>\n          <k2>0.1</k2>\n          <k3>0.0</k3>\n          <p1>0.0</p1>\n          <p2>0.0</p2>\n          <center>0.5 0.5</center>\n        </distortion>\n\n        \x3c!-- Camera intrinsics --\x3e\n        <intrinsics>\n          <fx>800.0</fx>\n          <fy>800.0</fy>\n          <cx>640.0</cx>\n          <cy>360.0</cy>\n        </intrinsics>\n\n        \x3c!-- Noise model for realism --\x3e\n        <noise>\n          <type>gaussian</type>\n          <mean>0.0</mean>\n          <stddev>0.01</stddev>\n        </noise>\n      </plugin>\n    </link>\n  </model>\n</sdf>\n'})}),"\n",(0,a.jsx)(e.h3,{id:"lidar-simulation",children:"LIDAR Simulation"}),"\n",(0,a.jsx)(e.p,{children:"LIDAR sensors provide distance measurements essential for navigation and obstacle avoidance. Simulation must account for range limits, angular resolution, and measurement noise."}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-xml",children:'\x3c!-- lidar_sensor.sdf --\x3e\n<sdf version="1.10">\n  <model name="head_lidar">\n    <link name="lidar_link">\n      <pose>0 0 0.1 0 0 0</pose>\n\n      <plugin name="lidar_plugin" filename="libgazebo_ros_laser.so">\n        <ros>\n          <namespace>/humanoid</namespace>\n          <remapping>scan:=lidar/scan</remapping>\n          <remapping>pointcloud:=lidar/points</remapping>\n        </ros>\n\n        <topic_name>/humanoid/lidar/scan</topic_name>\n        <frame_name>lidar_link</frame_name>\n\n        \x3c!-- 2D LIDAR configuration --\x3e\n        <laser_scan>\n          <sampling>360</sampling>\n          <range>\n            <min>0.1</min>\n            <max>30.0</max>\n            <resolution>0.01</resolution>\n          </range>\n          <angle>\n            <min>-3.14159</min>\n            <max>3.14159</max>\n            <resolution>0.0087</resolution>  \x3c!-- 0.5 degrees --\x3e\n          </angle>\n        </laser_scan>\n\n        \x3c!-- Noise parameters --\x3e\n        <noise>\n          <type>gaussian</type>\n          <mean>0.0</mean>\n          <stddev>0.02</stddev>\n        </noise>\n\n        \x3c!-- Multiple echo settings --\x3e\n        <num_echoes>2</num_echoes>\n        <cadenary>true</cadenary>\n      </plugin>\n    </link>\n  </model>\n</sdf>\n'})}),"\n",(0,a.jsx)(e.h3,{id:"imu-simulation",children:"IMU Simulation"}),"\n",(0,a.jsx)(e.p,{children:"IMU simulation must account for bias drift, scale factors, and cross-axis sensitivity. These imperfections are critical for algorithm development as they affect state estimation accuracy."}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-xml",children:'\x3c!-- imu_sensor.sdf --\x3e\n<sdf version="1.10">\n  <model name="pelvis_imu">\n    <link name="imu_link">\n      <pose>0 0 0.02 0 0 0</pose>\n\n      <plugin name="imu_plugin" filename="libgazebo_ros_imu.so">\n        <ros>\n          <namespace>/humanoid</namespace>\n          <remapping>imu:=imu/data</remapping>\n        </ros>\n\n        <frame_name>imu_link</frame_name>\n        <topic_name>/humanoid/imu/data</topic_name>\n\n        \x3c!-- Accelerometer configuration --\x3e\n        <acceleration>\n          <x>\n            <noise type="gaussian">\n              <mean>0.0</mean>\n              <stddev>0.002</stddev>  \x3c!-- 2 mg RMS noise --\x3e\n            </noise>\n            <bias>0.0</bias>\n            <scale_factor>1.0</scale_factor>\n          </x>\n          <y>\n            <noise type="gaussian">\n              <mean>0.0</mean>\n              <stddev>0.002</stddev>\n            </noise>\n          </y>\n          <z>\n            <noise type="gaussian">\n              <mean>0.0</mean>\n              <stddev>0.002</stddev>\n            </noise>\n            <bias>9.81</bias>  \x3c!-- Gravity at rest --\x3e\n          </z>\n        </acceleration>\n\n        \x3c!-- Gyroscope configuration --\x3e\n        <gyroscope>\n          <x>\n            <noise type="gaussian">\n              <mean>0.0</mean>\n              <stddev>0.0005</stddev>  \x3c!-- 0.05 deg/s RMS --\x3e\n            </noise>\n            <bias>0.001</bias>\n            <scale_factor>1.0</scale_factor>\n          </x>\n          <y>\n            <noise type="gaussian">\n              <mean>0.0</mean>\n              <stddev>0.0005</stddev>\n            </noise>\n          </y>\n          <z>\n            <noise type="gaussian">\n              <mean>0.0</mean>\n              <stddev>0.0005</stddev>\n            </noise>\n          </z>\n        </gyroscope>\n\n        \x3c!-- Update rate --\x3e\n        <update_rate>200</update_rate>\n      </plugin>\n    </link>\n  </model>\n</sdf>\n'})}),"\n",(0,a.jsx)(e.h3,{id:"complete-sensor-integration",children:"Complete Sensor Integration"}),"\n",(0,a.jsx)(e.p,{children:"The following Python code demonstrates sensor integration with ROS 2:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\n"""\nHumanoid Robot Sensor Integration for Simulation\n\nThis module provides sensor interfaces for reading simulated\nsensor data in Gazebo and converting it to usable formats.\n"""\n\nimport rclpy\nfrom rclpy.node import Node\nfrom rclpy.qos import QoSProfile, ReliabilityPolicy, DurabilityPolicy\nfrom sensor_msgs.msg import Image, CameraInfo, LaserScan, Imu\nfrom geometry_msgs.msg import WrenchStamped, TransformStamped\nfrom nav_msgs.msg import Odometry\nfrom std_msgs.msg import Float64MultiArray\nimport numpy as np\nfrom dataclasses import dataclass\nfrom typing import Optional, Tuple, List\nimport cv2\nfrom cv_bridge import CvBridge\n\n\n@dataclass\nclass SensorConfig:\n    """Configuration for simulated sensors."""\n    frame_id: str\n    topic: str\n    update_rate: float = 100.0\n    noise_stddev: float = 0.0\n    bias: float = 0.0\n\n\nclass HumanoidSensorInterface(Node):\n    """\n    Unified sensor interface for humanoid robot simulation.\n\n    Provides standardized access to all simulated sensors including\n    cameras, LIDAR, IMU, and force/torque sensors.\n    """\n\n    def __init__(self):\n        super().__init__(\'humanoid_sensor_interface\')\n\n        # QoS profile for sensor data\n        self.sensor_qos = QoSProfile(\n            reliability=ReliabilityPolicy.BEST_EFFORT,\n            durability=DurabilityPolicy.VOLATILE,\n            depth=1\n        )\n\n        # Camera configuration\n        self.declare_parameter(\'camera.frame_id\', \'head_camera_link\')\n        self.declare_parameter(\'camera.image_topic\', \'/humanoid/camera/image_raw\')\n        self.declare_parameter(\'camera.info_topic\', \'/humanoid/camera/camera_info\')\n        self.declare_parameter(\'camera.width\', 1280)\n        self.declare_parameter(\'camera.height\', 720)\n\n        # LIDAR configuration\n        self.declare_parameter(\'lidar.frame_id\', \'lidar_link\')\n        self.declare_parameter(\'lidar.topic\', \'/humanoid/lidar/scan\')\n        self.declare_parameter(\'lidar.min_range\', 0.1)\n        self.declare_parameter(\'lidar.max_range\', 30.0)\n\n        # IMU configuration\n        self.declare_parameter(\'imu.frame_id\', \'imu_link\')\n        self.declare_parameter(\'imu.topic\', \'/humanoid/imu/data\')\n        self.declare_parameter(\'imu.update_rate\', 200.0)\n\n        # Initialize CV bridge for image processing\n        self.cv_bridge = CvBridge()\n\n        # Sensor data storage\n        self.latest_image: Optional[Image] = None\n        self.latest_lidar: Optional[LaserScan] = None\n        self.latest_imu: Optional[Imu] = None\n        self.latest_ft_left: Optional[WrenchStamped] = None\n        self.latest_ft_right: Optional[WrenchStamped] = None\n\n        # Initialize subscribers\n        self._init_subscribers()\n\n        self.get_logger().info("Humanoid Sensor Interface initialized")\n\n    def _init_subscribers(self):\n        """Initialize all sensor subscribers."""\n        # Camera subscribers\n        self.image_sub = self.create_subscription(\n            Image,\n            \'/humanoid/camera/image_raw\',\n            self.image_callback,\n            self.sensor_qos\n        )\n\n        self.info_sub = self.create_subscription(\n            CameraInfo,\n            \'/humanoid/camera/camera_info\',\n            self.info_callback,\n            self.sensor_qos\n        )\n\n        # LIDAR subscriber\n        self.lidar_sub = self.create_subscription(\n            LaserScan,\n            \'/humanoid/lidar/scan\',\n            self.lidar_callback,\n            self.sensor_qos\n        )\n\n        # IMU subscriber\n        self.imu_sub = self.create_subscription(\n            Imu,\n            \'/humanoid/imu/data\',\n            self.imu_callback,\n            self.sensor_qos\n        )\n\n        # Force/torque subscribers\n        self.ft_left_sub = self.create_subscription(\n            WrenchStamped,\n            \'/humanoid/left_foot/ft\',\n            self.ft_left_callback,\n            self.sensor_qos\n        )\n\n        self.ft_right_sub = self.create_subscription(\n            WrenchStamped,\n            \'/humanoid/right_foot/ft\',\n            self.ft_right_callback,\n            self.sensor_qos\n        )\n\n    def image_callback(self, msg: Image):\n        """Process incoming camera image."""\n        self.latest_image = msg\n\n    def info_callback(self, msg: CameraInfo):\n        """Store camera calibration information."""\n        self.camera_info = msg\n\n    def lidar_callback(self, msg: LaserScan):\n        """Process incoming LIDAR scan."""\n        self.latest_lidar = msg\n\n    def imu_callback(self, msg: Imu):\n        """Process incoming IMU data."""\n        self.latest_imu = msg\n\n    def ft_left_callback(self, msg: WrenchStamped):\n        """Process left foot force/torque data."""\n        self.latest_ft_left = msg\n\n    def ft_right_callback(self, msg: WrenchStamped):\n        """Process right foot force/torque data."""\n        self.latest_ft_right = msg\n\n    def get_latest_image(self) -> Optional[np.ndarray]:\n        """Get latest image as numpy array."""\n        if self.latest_image is None:\n            return None\n        try:\n            return self.cv_bridge.imgmsg_to_cv2(\n                self.latest_image, desired_encoding=\'bgr8\'\n            )\n        except Exception as e:\n            self.get_logger().error(f"Image conversion failed: {e}")\n            return None\n\n    def get_latest_scan(self) -> Tuple[Optional[np.ndarray], Optional[np.ndarray]]:\n        """\n        Get latest LIDAR scan data.\n\n        Returns:\n            Tuple of (ranges, angles) arrays, or (None, None) if no data.\n        """\n        if self.latest_lidar is None:\n            return None, None\n\n        ranges = np.array(self.latest_lidar.ranges)\n        angles = np.linspace(\n            self.latest_lidar.angle_min,\n            self.latest_lidar.angle_max,\n            len(ranges)\n        )\n\n        return ranges, angles\n\n    def get_latest_imu_reading(self) -> Optional[Tuple[np.ndarray, np.ndarray]]:\n        """\n        Get latest IMU readings.\n\n        Returns:\n            Tuple of (linear_acceleration, angular_velocity) arrays.\n        """\n        if self.latest_imu is None:\n            return None\n\n        accel = np.array([\n            self.latest_imu.linear_acceleration.x,\n            self.latest_imu.linear_acceleration.y,\n            self.latest_imu.linear_acceleration.z\n        ])\n\n        gyro = np.array([\n            self.latest_imu.angular_velocity.x,\n            self.latest_imu.angular_velocity.y,\n            self.latest_imu.angular_velocity.z\n        ])\n\n        return accel, gyro\n\n    def get_center_of_pressure(self) -> Tuple[float, float]:\n        """\n        Calculate center of pressure from foot force/torque sensors.\n\n        Returns:\n            Tuple of (cop_x, cop_y) in foot frame coordinates.\n        """\n        fx_l = fy_l = tz_l = 0.0\n        fx_r = fy_r = tz_r = 0.0\n\n        if self.latest_ft_left:\n            fx_l = self.latest_ft_left.wrench.force.x\n            fy_l = self.latest_ft_left.wrench.force.y\n            tz_l = self.latest_ft_left.wrench.torque.z\n\n        if self.latest_ft_right:\n            fx_r = self.latest_ft_right.wrench.force.x\n            fy_r = self.latest_ft_right.wrench.force.y\n            tz_r = self.latest_ft_right.wrench.torque.z\n\n        # Combined forces\n        fx_total = fx_l + fx_r\n        fz_total = fy_l + fy_r  # Y force corresponds to Z moment\n\n        # Center of pressure calculation\n        if abs(fx_total) > 1.0:  # Minimum force threshold\n            cop_x = (tz_r - tz_l) / fx_total\n        else:\n            cop_x = 0.0\n\n        if abs(fz_total) > 1.0:\n            cop_y = (fx_r * 0.12 - fx_l * 0.12) / fz_total\n        else:\n            cop_y = 0.0\n\n        return cop_x, cop_y\n\n\ndef main(args=None):\n    """Run the sensor interface node."""\n    rclpy.init(args=args)\n\n    try:\n        interface = HumanoidSensorInterface()\n        rclpy.spin(interface)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        rclpy.shutdown()\n\n\nif __name__ == "__main__":\n    main()\n'})}),"\n",(0,a.jsx)(e.h2,{id:"36-unity-for-robot-visualization",children:"3.6 Unity for Robot Visualization"}),"\n",(0,a.jsx)(e.p,{children:"While Gazebo excels at physics simulation, Unity provides superior rendering capabilities for visualization, user interfaces, and photorealistic rendering. Integrating Unity with ROS 2 enables the best of both worlds: accurate physics and compelling visualization."}),"\n",(0,a.jsx)(e.h3,{id:"ros-unity-integration-architecture",children:"ROS-Unity Integration Architecture"}),"\n",(0,a.jsx)(e.p,{children:"The integration between Unity and ROS 2 requires a communication bridge. The ROS TCP Endpoint package in Unity receives data from ROS topics, while the Unity-ROS bridge sends commands and receives state updates."}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-csharp",children:'// C# script for Unity - ROS 2 Connection Manager\nusing UnityEngine;\nusing ROS2;\nusing System.Collections.Generic;\n\npublic class ROSConnectionManager : MonoBehaviour\n{\n    // ROS 2 node and publisher handles\n    private Node ros_node;\n    private Publisher<JointStateMsg> joint_state_pub;\n    private Publisher<OdometryMsg> odometry_pub;\n    private Subscriber<JointTrajectoryMsg> trajectory_sub;\n\n    // Joint state storage\n    private float[] joint_positions;\n    private float[] joint_velocities;\n    private string[] joint_names;\n\n    // Connection settings\n    private string ros_domain = "0";\n    private string ros_ip = "127.0.0.1";\n    private int ros_port = 9090;\n\n    void Start()\n    {\n        // Initialize ROS 2\n        var options = new RCLdotnet().CreateNodeOptions(ros_domain);\n        ros_node = new Node("unity_visualization", options);\n\n        // Create publishers\n        joint_state_pub = ros_node.CreatePublisher<JointStateMsg>(\n            "/humanoid/joint_states"\n        );\n        odometry_pub = ros_node.CreatePublisher<OdometryMsg>(\n            "/humanoid/odometry"\n        );\n\n        // Create subscriber for trajectory commands\n        trajectory_sub = ros_node.CreateSubscriber<JointTrajectoryMsg>(\n            "/humanoid/trajectory_command",\n            TrajectoryCallback\n        );\n\n        // Initialize joint arrays\n        InitializeJoints();\n\n        Debug.Log("ROS-Unity connection established");\n    }\n\n    void InitializeJoints()\n    {\n        // Define all humanoid joint names\n        joint_names = new string[] {\n            "left_hip_yaw", "left_hip_roll", "left_hip_pitch",\n            "left_knee", "left_ankle_pitch", "left_ankle_roll",\n            "right_hip_yaw", "right_hip_roll", "right_hip_pitch",\n            "right_knee", "right_ankle_pitch", "right_ankle_roll",\n            "waist_yaw", "waist_pitch", "waist_roll",\n            "left_shoulder_pitch", "left_shoulder_roll", "left_shoulder_yaw",\n            "left_elbow", "left_wrist_roll", "left_wrist_pitch",\n            "right_shoulder_pitch", "right_shoulder_roll", "right_shoulder_yaw",\n            "right_elbow", "right_wrist_roll", "right_wrist_pitch",\n            "neck_pitch", "neck_yaw"\n        };\n\n        joint_positions = new float[joint_names.Length];\n        joint_velocities = new float[joint_names.Length];\n    }\n\n    void Update()\n    {\n        // Process ROS callbacks\n        RCLdotnet.SpinOnce(ros_node, 0.01);\n\n        // Read joint positions from Unity transforms\n        UpdateJointPositions();\n\n        // Publish joint states\n        PublishJointStates();\n    }\n\n    void UpdateJointPositions()\n    {\n        // Read joint positions from Unity GameObjects\n        for (int i = 0; i < joint_names.Length; i++)\n        {\n            var joint = GameObject.Find(joint_names[i]);\n            if (joint != null)\n            {\n                joint_positions[i] = joint.transform.localRotation.eulerAngles.x;\n                joint_velocities[i] = 0.0f;  // Would calculate from delta\n            }\n        }\n    }\n\n    void PublishJointStates()\n    {\n        var msg = new JointStateMsg();\n\n        // Set header timestamp\n        // Note: Would use actual ROS time in production\n        msg.Header.Stamp.Sec = (int)Time.time;\n        msg.Header.Stamp.Nanosec = (uint)((Time.time % 1.0) * 1e9);\n        msg.Header.Frame_id = "world";\n\n        msg.Name = joint_names;\n        msg.Position = joint_positions;\n        msg.Velocity = joint_velocities;\n        msg.Effort = new double[joint_names.Length];  // Not available in Unity\n\n        joint_state_pub.Publish(msg);\n    }\n\n    void TrajectoryCallback(JointTrajectoryMsg msg)\n    {\n        // Process incoming trajectory commands\n        if (msg.Points.Length > 0)\n        {\n            var firstPoint = msg.Points[0];\n            for (int i = 0; i < joint_names.Length && i < msg.JointNames.Length; i++)\n            {\n                int jointIndex = System.Array.IndexOf(joint_names, msg.JointNames[i]);\n                if (jointIndex >= 0)\n                {\n                    // Apply position command to Unity joint\n                    var joint = GameObject.Find(joint_names[jointIndex]);\n                    if (joint != null && firstPoint.Positions.Length > i)\n                    {\n                        // Rotate joint to target position\n                        var targetRot = Quaternion.Euler(\n                            (float)(firstPoint.Positions[i] * Mathf.Rad2Deg),\n                            0, 0\n                        );\n                        joint.transform.localRotation = targetRot;\n                    }\n                }\n            }\n        }\n    }\n\n    void OnDestroy()\n    {\n        // Cleanup ROS resources\n        joint_state_pub.Dispose();\n        odometry_pub.Dispose();\n        trajectory_sub.Dispose();\n        ros_node.Dispose();\n    }\n}\n'})}),"\n",(0,a.jsx)(e.h3,{id:"visualization-best-practices",children:"Visualization Best Practices"}),"\n",(0,a.jsx)(e.p,{children:"Effective humanoid robot visualization requires attention to rendering quality, camera positioning, and animation smoothness. The following guidelines ensure professional-quality visualizations:"}),"\n",(0,a.jsx)(e.p,{children:"Camera setup should include multiple view angles: a third-person follow camera, an over-the-shoulder view for arm manipulation tasks, and a first-person view from the robot head. Smooth camera transitions using cinematographic techniques enhance the viewing experience."}),"\n",(0,a.jsx)(e.p,{children:"Lighting should balance realism with clarity. HDRI environment lighting provides natural reflections and ambient illumination. Key, fill, and rim lighting setups emphasize robot form and silhouette. Dynamic lighting that responds to robot motion adds visual interest."}),"\n",(0,a.jsx)(e.p,{children:"Material rendering should accurately represent robot materials: metallic finishes with appropriate roughness and clear coat, plastic components with subsurface scattering for translucency, and fabric or rubber materials with proper normal mapping."}),"\n",(0,a.jsx)(e.h2,{id:"37-simulation-launch-and-control",children:"3.7 Simulation Launch and Control"}),"\n",(0,a.jsx)(e.p,{children:"Complete simulation startup requires coordinating multiple components: the physics world, robot description, sensor plugins, and visualization tools. The following ROS 2 launch file provides a comprehensive example."}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"#!/usr/bin/env python3\n\"\"\"\nHumanoid Robot Simulation Launch File\n\nThis launch file starts the complete simulation environment including\nGazebo, robot description, sensors, and visualization tools.\n\"\"\"\n\nimport os\nfrom launch import LaunchDescription\nfrom launch.actions import IncludeLaunchDescription, DeclareLaunchArgument, ExecuteProcess\nfrom launch.launch_description_sources import PythonLaunchDescriptionSource\nfrom launch.substitutions import LaunchConfiguration, PathJoinSubstitution\nfrom launch_ros.substitutions import FindPackageShare\nfrom launch_ros.actions import Node\nfrom launch.conditions import IfCondition\n\n\ndef generate_launch_description():\n    \"\"\"Generate the complete simulation launch description.\"\"\"\n\n    # Declare launch arguments\n    use_sim_time = DeclareLaunchArgument(\n        'use_sim_time',\n        default_value='true',\n        description='Use simulation time'\n    )\n\n    robot_model = DeclareLaunchArgument(\n        'robot_model',\n        default_value='atlas_v2',\n        description='Robot model identifier'\n    )\n\n    world_file = DeclareLaunchArgument(\n        'world',\n        default_value='humanoid_lab.sdf',\n        description='Gazebo world file'\n    )\n\n    gui = DeclareLaunchArgument(\n        'gui',\n        default_value='true',\n        description='Show Gazebo GUI'\n    )\n\n    rviz = DeclareLaunchArgument(\n        'rviz',\n        default_value='true',\n        description='Show RViz visualization'\n    )\n\n    # Package shares\n    pkg_share = FindPackageShare('humanoid_gazebo')\n    pkg_description = FindPackageShare('humanoid_description')\n    pkg_control = FindPackageShare('humanoid_control')\n\n    # Paths\n    urdf_file = PathJoinSubstitution([\n        pkg_description, 'urdf', 'humanoid.urdf.xacro'\n    ])\n\n    world_path = PathJoinSubstitution([\n        pkg_share, 'worlds', LaunchConfiguration('world')\n    ])\n\n    rviz_config = PathJoinSubstitution([\n        pkg_control, 'rviz', 'humanoid_simulation.rviz'\n    ])\n\n    # Create launch description\n    ld = LaunchDescription()\n\n    # Add arguments\n    ld.add_action(use_sim_time)\n    ld.add_action(robot_model)\n    ld.add_action(world_file)\n    ld.add_action(gui)\n    ld.add_action(rviz)\n\n    # Gazebo server\n    gz_server = IncludeLaunchDescription(\n        PythonLaunchDescriptionSource([\n            PathJoinSubstitution([\n                FindPackageShare('gazebo_ros'),\n                'launch', 'gzserver.launch.py'\n            ])\n        ]),\n        launch_arguments={\n            'world': world_path,\n            'physics': 'dart',\n            'use_sim_time': LaunchConfiguration('use_sim_time'),\n        }.items(),\n        condition=IfCondition(LaunchConfiguration('gui'))\n    )\n    ld.add_action(gz_server)\n\n    # Gazebo client\n    gz_client = IncludeLaunchDescription(\n        PythonLaunchDescriptionSource([\n            PathJoinSubstitution([\n                FindPackageShare('gazebo_ros'),\n                'launch', 'gzclient.launch.py'\n            ])\n        ]),\n        condition=IfCondition(LaunchConfiguration('gui'))\n    )\n    ld.add_action(gz_client)\n\n    # Robot state publisher\n    robot_state_publisher = Node(\n        package='robot_state_publisher',\n        executable='robot_state_publisher',\n        name='robot_state_publisher',\n        parameters=[{\n            'robot_description': urdf_file,\n            'use_tf_static': True,\n            'use_sim_time': LaunchConfiguration('use_sim_time'),\n        }],\n        output='screen'\n    )\n    ld.add_action(robot_state_publisher)\n\n    # Spawn robot in Gazebo\n    spawn_robot = Node(\n        package='gazebo_ros',\n        executable='spawn_entity.py',\n        name='spawn_entity',\n        arguments=[\n            '-entity', 'atlas_humanoid',\n            '-file', urdf_file,\n            '-robot_namespace', 'humanoid',\n            '-x', '0.0',\n            '-y', '0.0',\n            '-z', '1.0',\n            '-R', '0.0',\n            '-P', '0.0',\n            '-Y', '0.0'\n        ],\n        output='screen'\n    )\n    ld.add_action(spawn_robot)\n\n    # Joint state publisher (Gazebo plugin)\n    joint_state_publisher = Node(\n        package='joint_state_publisher',\n        executable='joint_state_publisher',\n        name='joint_state_publisher',\n        parameters=[{\n            'use_sim_time': LaunchConfiguration('use_sim_time'),\n        }],\n        output='screen'\n    )\n    ld.add_action(joint_state_publisher)\n\n    # IMU filter node\n    imu_filter = Node(\n        package='imu_tools',\n        executable='imu_filter_node',\n        name='imu_filter',\n        parameters=[{\n            'use_sim_time': LaunchConfiguration('use_sim_time'),\n            'world_frame': 'enu',\n            'orientation_stddev': 0.1,\n        }],\n        remappings=[\n            ('imu_in', '/humanoid/imu/data'),\n            ('imu_out', '/humanoid/imu/filtered')\n        ],\n        output='screen'\n    )\n    ld.add_action(imu_filter)\n\n    # RViz visualization\n    rviz_node = Node(\n        package='rviz2',\n        executable='rviz2',\n        name='rviz2',\n        arguments=['-d', rviz_config],\n        parameters=[{\n            'use_sim_time': LaunchConfiguration('use_sim_time'),\n        }],\n        condition=IfCondition(LaunchConfiguration('rviz')),\n        output='screen'\n    )\n    ld.add_action(rviz_node)\n\n    # Robot controller\n    robot_controller = Node(\n        package='humanoid_control',\n        executable='balance_controller',\n        name='balance_controller',\n        parameters=[\n            PathJoinSubstitution([pkg_control, 'config', 'control_params.yaml']),\n            {'use_sim_time': LaunchConfiguration('use_sim_time')}\n        ],\n        output='screen'\n    )\n    ld.add_action(robot_controller)\n\n    return ld\n"})}),"\n",(0,a.jsx)(e.h2,{id:"chapter-summary",children:"Chapter Summary"}),"\n",(0,a.jsx)(e.p,{children:"This chapter covered the essential aspects of robot simulation for humanoid robotics development:"}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Simulation Importance"}),": Robot simulation enables safe algorithm development, cost-effective testing, and scenarios impossible with physical hardware."]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Gazebo Configuration"}),": Setting up simulation environments with appropriate physics engines, thread configurations, and resource allocation."]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Robot Description Formats"}),": URDF provides standardized robot description for kinematics and basic properties, while SDF offers more comprehensive modeling capabilities."]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Physics Simulation"}),": Joint dynamics, contact modeling, and friction configuration are critical for realistic humanoid behavior in simulation."]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Sensor Simulation"}),": Camera, LIDAR, and IMU simulation with realistic noise models prepares algorithms for physical deployment."]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Unity Visualization"}),": High-fidelity rendering complements physics simulation for visualization and communication purposes."]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Launch and Control"}),": Complete launch files coordinate all simulation components for reproducible development environments."]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"key-concepts",children:"Key Concepts"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"URDF/SDF"}),": Robot description formats providing kinematics, visual, and collision properties"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Physics Engines"}),": DART, ODE, and Bullet provide different accuracy/performance tradeoffs"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Sensor Plugins"}),": Gazebo plugins simulate sensor behavior with configurable noise"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"ROS Integration"}),": Seamless integration between ROS 2 and simulation environments"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Visualization"}),": Unity provides photorealistic rendering complementary to Gazebo"]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"hardware-requirements-reference",children:"Hardware Requirements Reference"}),"\n",(0,a.jsxs)(e.table,{children:[(0,a.jsx)(e.thead,{children:(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.th,{children:"Component"}),(0,a.jsx)(e.th,{children:"Minimum"}),(0,a.jsx)(e.th,{children:"Recommended"})]})}),(0,a.jsxs)(e.tbody,{children:[(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:"CPU"}),(0,a.jsx)(e.td,{children:"4-core @ 2.5 GHz"}),(0,a.jsx)(e.td,{children:"8-core @ 4.0 GHz"})]}),(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:"RAM"}),(0,a.jsx)(e.td,{children:"8 GB"}),(0,a.jsx)(e.td,{children:"32 GB DDR4"})]}),(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:"GPU"}),(0,a.jsx)(e.td,{children:"Integrated"}),(0,a.jsx)(e.td,{children:"NVIDIA RTX 3060+"})]}),(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:"Storage"}),(0,a.jsx)(e.td,{children:"64 GB SSD"}),(0,a.jsx)(e.td,{children:"256 GB NVMe SSD"})]}),(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:"Physics Rate"}),(0,a.jsx)(e.td,{children:"500 Hz"}),(0,a.jsx)(e.td,{children:"1000 Hz"})]})]})]}),"\n",(0,a.jsx)(e.h3,{id:"further-reading",children:"Further Reading"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:["Gazebo Documentation: ",(0,a.jsx)(e.a,{href:"https://gazebosim.org/docs",children:"https://gazebosim.org/docs"})]}),"\n",(0,a.jsxs)(e.li,{children:["ROS 2 Control: ",(0,a.jsx)(e.a,{href:"https://control.ros.org/",children:"https://control.ros.org/"})]}),"\n",(0,a.jsxs)(e.li,{children:["Unity Robotics Hub: ",(0,a.jsx)(e.a,{href:"https://github.com/Unity-Technologies/Unity-Robotics-Hub",children:"https://github.com/Unity-Technologies/Unity-Robotics-Hub"})]}),"\n",(0,a.jsxs)(e.li,{children:["DARwin-OP2 Documentation: ",(0,a.jsx)(e.a,{href:"https://github.com/ROBOTIS-GIT/ROBOTIS-Documents",children:"https://github.com/ROBOTIS-GIT/ROBOTIS-Documents"})]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"next-chapter",children:"Next Chapter"}),"\n",(0,a.jsxs)(e.p,{children:["Chapter 4 explores ",(0,a.jsx)(e.strong,{children:"Isaac Sim"})," for GPU-accelerated simulation, enabling high-performance simulation for training perception models and reinforcement learning with realistic rendering and physics."]}),"\n",(0,a.jsx)(e.hr,{}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Part 2: ROS 2 Fundamentals"})," | ",(0,a.jsx)(e.a,{href:"part-2-ros2/02a-week-3-5-overview",children:"Weeks 3-5 Overview"})," | ",(0,a.jsx)(e.a,{href:"part-3-simulation/gazebo-unity-simulation",children:"Part 3: Simulation"})," | ",(0,a.jsx)(e.a,{href:"part-4-isaac/nvidia-isaac-platform",children:"Part 4: NVIDIA Isaac"})]})]})}function m(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,a.jsx)(e,{...n,children:(0,a.jsx)(d,{...n})}):d(n)}}}]);