"use strict";(globalThis.webpackChunkbook=globalThis.webpackChunkbook||[]).push([[585],{3585:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>m,frontMatter:()=>r,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"part-4-isaac/04a-week-8-10-overview","title":"Weeks 8-10: NVIDIA Isaac Platform","description":"This section provides a structured learning plan for mastering the NVIDIA Isaac ecosystem for physical AI development. The three-week curriculum builds practical skills in high-fidelity simulation, AI-powered perception, GPU-accelerated reinforcement learning, and sim-to-real transfer techniques.","source":"@site/docs/part-4-isaac/04a-week-8-10-overview.md","sourceDirName":"part-4-isaac","slug":"/part-4-isaac/04a-week-8-10-overview","permalink":"/Ary-s-Physical-Humanoid-Robotics/docs/part-4-isaac/04a-week-8-10-overview","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/part-4-isaac/04a-week-8-10-overview.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"title":"Weeks 8-10: NVIDIA Isaac Platform","sidebar_position":5},"sidebar":"tutorialSidebar","previous":{"title":"NVIDIA Isaac Platform","permalink":"/Ary-s-Physical-Humanoid-Robotics/docs/part-4-isaac/nvidia-isaac-platform"},"next":{"title":"Humanoid Robot Development","permalink":"/Ary-s-Physical-Humanoid-Robotics/docs/part-5-humanoid/humanoid-robot-development"}}');var t=i(4848),a=i(8453);const r={title:"Weeks 8-10: NVIDIA Isaac Platform",sidebar_position:5},o="Part 4: NVIDIA Isaac Platform - Weeks 8-10 Overview",l={},c=[{value:"Week 8: Isaac Sim Setup and AI-Powered Perception",id:"week-8-isaac-sim-setup-and-ai-powered-perception",level:2},{value:"Learning Objectives",id:"learning-objectives",level:3},{value:"Core Topics",id:"core-topics",level:3},{value:"1. Isaac Sim Installation and Configuration",id:"1-isaac-sim-installation-and-configuration",level:4},{value:"2. USD-Based Robot Description",id:"2-usd-based-robot-description",level:4},{value:"3. GPU-Accelerated Perception Pipelines",id:"3-gpu-accelerated-perception-pipelines",level:4},{value:"Key Concepts to Master",id:"key-concepts-to-master",level:3},{value:"Practice Exercises",id:"practice-exercises",level:3},{value:"Estimated Time Commitment",id:"estimated-time-commitment",level:3},{value:"Week 9: Isaac Gym and Manipulation",id:"week-9-isaac-gym-and-manipulation",level:2},{value:"Learning Objectives",id:"learning-objectives-1",level:3},{value:"Core Topics",id:"core-topics-1",level:3},{value:"1. Isaac Gym Fundamentals",id:"1-isaac-gym-fundamentals",level:4},{value:"2. Reward Design for Manipulation",id:"2-reward-design-for-manipulation",level:4},{value:"3. Policy Training and Evaluation",id:"3-policy-training-and-evaluation",level:4},{value:"Key Concepts to Master",id:"key-concepts-to-master-1",level:3},{value:"Practice Exercises",id:"practice-exercises-1",level:3},{value:"Estimated Time Commitment",id:"estimated-time-commitment-1",level:3},{value:"Week 10: Reinforcement Learning and Sim-to-Real Transfer",id:"week-10-reinforcement-learning-and-sim-to-real-transfer",level:2},{value:"Learning Objectives",id:"learning-objectives-2",level:3},{value:"Core Topics",id:"core-topics-2",level:3},{value:"1. Domain Randomization",id:"1-domain-randomization",level:4},{value:"2. System Identification",id:"2-system-identification",level:4},{value:"3. Physical Deployment",id:"3-physical-deployment",level:4},{value:"Key Concepts to Master",id:"key-concepts-to-master-2",level:3},{value:"Practice Exercises",id:"practice-exercises-2",level:3},{value:"Estimated Time Commitment",id:"estimated-time-commitment-2",level:3},{value:"Summary and Next Steps",id:"summary-and-next-steps",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"part-4-nvidia-isaac-platform---weeks-8-10-overview",children:"Part 4: NVIDIA Isaac Platform - Weeks 8-10 Overview"})}),"\n",(0,t.jsx)(n.p,{children:"This section provides a structured learning plan for mastering the NVIDIA Isaac ecosystem for physical AI development. The three-week curriculum builds practical skills in high-fidelity simulation, AI-powered perception, GPU-accelerated reinforcement learning, and sim-to-real transfer techniques."}),"\n",(0,t.jsx)(n.h2,{id:"week-8-isaac-sim-setup-and-ai-powered-perception",children:"Week 8: Isaac Sim Setup and AI-Powered Perception"}),"\n",(0,t.jsx)(n.h3,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,t.jsx)(n.p,{children:"By the end of Week 8, you will be able to:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Install and configure Isaac Sim on RTX-powered workstations and servers"}),"\n",(0,t.jsx)(n.li,{children:"Create simulation environments with humanoid robots using USD representations"}),"\n",(0,t.jsx)(n.li,{children:"Implement GPU-accelerated computer vision pipelines for object detection and segmentation"}),"\n",(0,t.jsx)(n.li,{children:"Configure realistic sensor simulation including cameras, depth sensors, and IMUs"}),"\n",(0,t.jsx)(n.li,{children:"Generate synthetic datasets for training perception models"}),"\n",(0,t.jsx)(n.li,{children:"Integrate Isaac perception outputs with ROS 2 for downstream robotics applications"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"core-topics",children:"Core Topics"}),"\n",(0,t.jsx)(n.h4,{id:"1-isaac-sim-installation-and-configuration",children:"1. Isaac Sim Installation and Configuration"}),"\n",(0,t.jsx)(n.p,{children:"Isaac Sim requires specific hardware and software prerequisites to function correctly. The installation process involves setting up NVIDIA Omniverse, installing the Isaac Sim extension, and configuring the development environment. Understanding these requirements prevents common setup issues and ensures optimal performance."}),"\n",(0,t.jsx)(n.p,{children:"The installation process begins with NVIDIA Omniverse Launcher installation. After launcher setup, Isaac Sim can be installed as a kit extension. The installation size is substantial (10+ GB) due to the comprehensive simulation assets and dependencies. Post-installation configuration includes setting up Python environments, configuring GPU rendering options, and establishing USD asset paths."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'# Isaac Sim installation steps (Ubuntu 22.04)\n\n# 1. Install NVIDIA driver (if not already installed)\nsudo apt update\nsudo apt install nvidia-driver-535\nsudo reboot\n\n# 2. Download Omniverse Launcher from NVIDIA website\n# https://www.nvidia.com/en-us/omniverse/download/\nchmod +x OmniverseLauncher-linux-x86_64-*.AppImage\n./OmniverseLauncher-linux-x86_64-*.AppImage\n\n# 3. Install Isaac Sim through Omniverse Launcher\n# - Open Omniverse Launcher\n# - Go to "Exchange" tab\n# - Search for "Isaac Sim"\n# - Click Install\n\n# 4. Create Python virtual environment (recommended)\npython -m venv isaac-sim-env\nsource isaac-sim-env/bin/activate\n\n# 5. Set up environment variables\nexport OMNI_KIT_APP_NAME=isaac-sim\nexport ISAAC_SIM_PATH=$HOME/.local/share/ov/pkg/isaac_sim-*\nexport CARB_APP_PATH=$ISAAC_SIM_PATH/apps\nexport PYTHON_PATH=$ISAAC_SIM_PATH/python:$PYTHON_PATH\n\n# 6. Verify installation\ncd $ISAAC_SIM_PATH\n./python.sh scripts/examples/simple_env.py\n'})}),"\n",(0,t.jsx)(n.h4,{id:"2-usd-based-robot-description",children:"2. USD-Based Robot Description"}),"\n",(0,t.jsx)(n.p,{children:"Universal Scene Description (USD) forms the foundation for Isaac Sim asset management. Unlike URDF for traditional ROS robotics, USD provides a hierarchical scene graph with rich composition capabilities. Understanding USD composition, variants, and payloads enables efficient robot and environment representation."}),"\n",(0,t.jsx)(n.p,{children:"Humanoid robots in USD require careful articulation setup. The articulation root defines the kinematic and dynamic relationships between robot links and joints. Joint types including revolute, prismatic, and spherical must be configured with appropriate limits and dynamics parameters. Visual and collision geometry can be referenced from separate USD files, enabling asset reuse across projects."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'# Example: Creating humanoid robot articulation in USD\nfrom pxr import Usd, UsdGeom, UsdPhysics, Gf, Sdf\n\ndef create_humanoid_articulation(stage, prim_path, config):\n    """\n    Create a humanoid robot articulation in USD.\n\n    Args:\n        stage: USD stage to create articulation in\n        prim_path: Base path for the robot\n        config: Robot configuration dictionary\n    """\n    # Create Xform for robot root\n    robot_xform = UsdGeom.Xform.Define(stage, prim_path)\n\n    # Define articulation root\n    articulation = UsdPhysics.ArticulationRootAPI.Apply(\n        stage.GetPrimAtPath(f"{prim_path}/root_link")\n    )\n    articulation.CreateEnabledAttr(True)\n\n    # Create body schemas for each link\n    link_names = [\n        "pelvis", "torso", "head",\n        "left_shoulder", "left_upper_arm", "left_lower_arm", "left_hand",\n        "right_shoulder", "right_upper_arm", "right_lower_arm", "right_hand",\n        "left_hip", "left_upper_leg", "left_lower_leg", "left_foot",\n        "right_hip", "right_upper_leg", "right_lower_leg", "right_foot"\n    ]\n\n    for link_name in link_names:\n        link_path = f"{prim_path}/{link_name}"\n        link = UsdGeom.Xform.Define(stage, link_path)\n\n        # Add rigid body and collision\n        UsdPhysics.RigidBodyAPI.Apply(stage.GetPrimAtPath(link_path))\n        UsdPhysics.CollisionAPI.Apply(stage.GetPrimAtPath(link_path))\n\n    # Create joints between adjacent links\n    joint_connections = [\n        ("pelvis", "torso", "revolute"),\n        ("torso", "head", "revolute"),\n        ("torso", "left_shoulder", "revolute"),\n        ("left_shoulder", "left_upper_arm", "revolute"),\n        ("left_upper_arm", "left_lower_arm", "revolute"),\n        ("left_lower_arm", "left_hand", "revolute"),\n        ("torso", "right_shoulder", "revolute"),\n        ("right_shoulder", "right_upper_arm", "revolute"),\n        ("right_upper_arm", "right_lower_arm", "revolute"),\n        ("right_lower_arm", "right_hand", "revolute"),\n        ("pelvis", "left_hip", "revolute"),\n        ("left_hip", "left_upper_leg", "revolute"),\n        ("left_upper_leg", "left_lower_leg", "revolute"),\n        ("left_lower_leg", "left_foot", "revolute"),\n        ("pelvis", "right_hip", "revolute"),\n        ("right_hip", "right_upper_leg", "revolute"),\n        ("right_upper_leg", "right_lower_leg", "revolute"),\n        ("right_lower_leg", "right_foot", "revolute"),\n    ]\n\n    for parent, child, joint_type in joint_connections:\n        create_joint(\n            stage,\n            f"{prim_path}/{parent}",\n            f"{prim_path}/{child}",\n            joint_type\n        )\n\n    return robot_xform\n\n\ndef create_joint(stage, parent_path, child_path, joint_type):\n    """Create a joint between two links."""\n    joint_path = f"{child_path}/joint"\n\n    if joint_type == "revolute":\n        joint = UsdPhysics.RevoluteJoint.Define(stage, joint_path)\n    elif joint_type == "prismatic":\n        joint = UsdPhysics.PrismaticJoint.Define(stage, joint_path)\n    else:\n        joint = UsdPhysics.Joint.Define(stage, joint_path)\n\n    # Set body references\n    joint.CreateBody0Rel().SetTargets([Sdf.Path(parent_path)])\n    joint.CreateBody1Rel().SetTargets([Sdf.Path(child_path)])\n\n    # Configure joint limits\n    if joint_type == "revolute":\n        joint.CreateLowerLimitAttr(-1.57)  # -90 degrees\n        joint.CreateUpperLimitAttr(1.57)   # 90 degrees\n        joint.CreateAxisAttr("Z")\n\n    return joint\n'})}),"\n",(0,t.jsx)(n.h4,{id:"3-gpu-accelerated-perception-pipelines",children:"3. GPU-Accelerated Perception Pipelines"}),"\n",(0,t.jsx)(n.p,{children:"Modern perception relies on deep neural networks for object detection, segmentation, and depth estimation. Isaac provides optimized implementations that leverage GPU acceleration for real-time performance. Understanding these pipelines and their integration with simulation enables development of perception-capable robot systems."}),"\n",(0,t.jsx)(n.p,{children:"Object detection identifies and locates objects within camera images. Popular architectures include YOLO variants for real-time detection and Faster R-CNN for higher accuracy. Isaac integration uses TensorRT for optimized inference, achieving 100+ FPS on RTX GPUs. Detection outputs include bounding boxes, class labels, and confidence scores for downstream processing."}),"\n",(0,t.jsx)(n.p,{children:"Semantic segmentation classifies each pixel in an image into semantic categories. For humanoid robots, segmenting floors, walls, furniture, and objects enables scene understanding for navigation and manipulation. Segmentation networks process full-resolution images, requiring significant compute for real-time operation."}),"\n",(0,t.jsx)(n.p,{children:"Depth estimation from monocular images provides 3D information without specialized depth sensors. Neural networks trained on RGB-D datasets can predict dense depth maps from single images. These predictions enable 3D perception on platforms lacking depth sensors, though with reduced accuracy compared to direct depth measurement."}),"\n",(0,t.jsx)(n.h3,{id:"key-concepts-to-master",children:"Key Concepts to Master"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Isaac Sim Architecture"}),": Client-server model, USD composition, physics timestep management"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"GPU Pipeline"}),": TensorRT optimization, CUDA memory management, inference batching"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Sensor Simulation"}),": Camera models, noise injection, depth sensor characteristics"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"ROS 2 Integration"}),": Isaac-ROS bridges, topic remapping, message type conversions"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Synthetic Data Generation"}),": Domain randomization, augmentation strategies, dataset scaling"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"practice-exercises",children:"Practice Exercises"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Exercise 1: Isaac Sim Installation and Verification"})," (3 hours)"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Install Omniverse Launcher and Isaac Sim extension"}),"\n",(0,t.jsx)(n.li,{children:"Configure Python environment with required packages"}),"\n",(0,t.jsx)(n.li,{children:"Run built-in examples to verify installation"}),"\n",(0,t.jsx)(n.li,{children:"Benchmark GPU memory usage for different scene complexities"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Exercise 2: Humanoid Robot USD Creation"})," (4 hours)"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Create a simplified humanoid robot in USD format"}),"\n",(0,t.jsx)(n.li,{children:"Define articulation structure with appropriate joints"}),"\n",(0,t.jsx)(n.li,{children:"Configure collision geometry and mass properties"}),"\n",(0,t.jsx)(n.li,{children:"Load and visualize in Isaac Sim"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Exercise 3: Camera Simulation and Capture"})," (3 hours)"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Add camera sensors to the humanoid robot"}),"\n",(0,t.jsx)(n.li,{children:"Configure camera intrinsics (resolution, FOV, focal length)"}),"\n",(0,t.jsx)(n.li,{children:"Capture RGB and depth images from simulation"}),"\n",(0,t.jsx)(n.li,{children:"Export captured data for external processing"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Exercise 4: Object Detection Pipeline"})," (4 hours)"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Implement TensorRT model loading for detection"}),"\n",(0,t.jsx)(n.li,{children:"Process camera images through detection network"}),"\n",(0,t.jsx)(n.li,{children:"Visualize detection results with bounding boxes"}),"\n",(0,t.jsx)(n.li,{children:"Integrate with ROS 2 for topic publishing"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Exercise 5: Synthetic Dataset Generation"})," (4 hours)"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Set up domain randomization for object appearance"}),"\n",(0,t.jsx)(n.li,{children:"Generate 10,000 labeled images with varied conditions"}),"\n",(0,t.jsx)(n.li,{children:"Export in COCO format for downstream training"}),"\n",(0,t.jsx)(n.li,{children:"Verify dataset quality metrics"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"estimated-time-commitment",children:"Estimated Time Commitment"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Activity"}),(0,t.jsx)(n.th,{children:"Hours"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Reading and tutorials"}),(0,t.jsx)(n.td,{children:"8"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Exercise 1: Installation"}),(0,t.jsx)(n.td,{children:"3"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Exercise 2: USD Creation"}),(0,t.jsx)(n.td,{children:"4"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Exercise 3: Camera Setup"}),(0,t.jsx)(n.td,{children:"3"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Exercise 4: Detection"}),(0,t.jsx)(n.td,{children:"4"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Exercise 5: Dataset Gen"}),(0,t.jsx)(n.td,{children:"4"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Troubleshooting and review"}),(0,t.jsx)(n.td,{children:"4"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Total"})}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"30 hours"})})]})]})]}),"\n",(0,t.jsx)(n.h2,{id:"week-9-isaac-gym-and-manipulation",children:"Week 9: Isaac Gym and Manipulation"}),"\n",(0,t.jsx)(n.h3,{id:"learning-objectives-1",children:"Learning Objectives"}),"\n",(0,t.jsx)(n.p,{children:"By the end of Week 9, you will be able to:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Configure Isaac Gym for GPU-accelerated parallel simulation"}),"\n",(0,t.jsx)(n.li,{children:"Design reward functions for manipulation tasks"}),"\n",(0,t.jsx)(n.li,{children:"Implement RL training loops with PPO or SAC algorithms"}),"\n",(0,t.jsx)(n.li,{children:"Train policies for grasping, placement, and tool use"}),"\n",(0,t.jsx)(n.li,{children:"Evaluate policy performance using simulation metrics"}),"\n",(0,t.jsx)(n.li,{children:"Export trained policies for deployment"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"core-topics-1",children:"Core Topics"}),"\n",(0,t.jsx)(n.h4,{id:"1-isaac-gym-fundamentals",children:"1. Isaac Gym Fundamentals"}),"\n",(0,t.jsx)(n.p,{children:"Isaac Gym revolutionizes robot learning by running thousands of simulations in parallel on a single GPU. Traditional RL approaches use CPU-based simulation, limited by single-core performance. Isaac Gym's GPU-first architecture enables sample-efficient learning from billions of simulated interactions."}),"\n",(0,t.jsx)(n.p,{children:"The architecture separates Python training code from physics simulation. Physics runs entirely on GPU through PhysX, avoiding costly CPU-GPU data transfers. Training code accesses simulation state through GPU tensors, enabling vectorized operations across all environments simultaneously. This design scales directly with GPU capability, from RTX workstations to A100 data center GPUs."}),"\n",(0,t.jsx)(n.p,{children:"Environment design in Isaac Gym follows a pattern of environment creation, reset handling, and observation collection. Each environment contains a robot and task-relevant objects. The training loop steps all environments in parallel, collects experiences, and updates the policy. This parallel structure accelerates learning by orders of magnitude compared to serial simulation."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'# Example: Isaac Gym environment for object grasping\nimport numpy as np\nimport torch\nimport isaacgym\nfrom isaacgym import gymapi, gymtorch\n\nclass GraspingEnv:\n    """\n    Parallel grasping environment for Isaac Gym.\n    Multiple robot hands learn to grasp objects in parallel.\n    """\n\n    def __init__(\n        self,\n        num_envs: int = 4096,\n        num_obs: int = 45,\n        num_actions: int = 7,\n        device: str = "cuda"\n    ):\n        self.num_envs = num_envs\n        self.num_obs = num_obs\n        self.num_actions = num_actions\n        self.device = device\n\n        # Initialize gym\n        self.gym = gymapi.acquire_gym()\n\n        # Simulation parameters\n        self.sim_params = gymapi.SimParams()\n        self.sim_params.dt = 1.0 / 60.0\n        self.sim_params.num_substeps = 2\n        self.sim_params.use_gpu_pipeline = True\n\n        # Create simulation\n        self.sim = self.gym.create_sim(\n            device_id=0 if device == "cuda" else -1,\n            graphics_device_id=0 if device == "cuda" else -1,\n            sim_type=gymapi.SIM_PHYSX,\n            sim_params=self.sim_params\n        )\n\n        # Create environments\n        self._create_assets()\n        self._create_envs()\n\n        # Initialize state tensors\n        self._init_state_tensors()\n\n    def _create_assets(self):\n        """Load robot hand and object assets."""\n        # Robot hand asset\n        hand_asset_options = gymapi.AssetOptions()\n        hand_asset_options.fix_base_link = 0\n        hand_asset_options.disable_gravity = False\n        self.hand_asset = self.gym.load_asset(\n            self.sim, "assets", "robot_hand.urdf", hand_asset_options\n        )\n\n        # Object asset (cube)\n        object_asset_options = gymapi.AssetOptions()\n        object_asset_options.density = 1000.0\n        self.object_asset = self.gym.load_asset(\n            self.sim, "assets", "cube.usd", object_asset_options\n        )\n\n    def _create_envs(self):\n        """Create parallel environments."""\n        env_spacing = 0.6\n        num_per_row = int(np.sqrt(self.num_envs))\n\n        self.envs = []\n        self.hand_actors = []\n        self.object_actors = []\n\n        for i in range(self.num_envs):\n            env = self.gym.create_env(\n                self.sim,\n                env_spacing * (i % num_per_row),\n                env_spacing * (i // num_per_row),\n                env_spacing,\n                num_per_row\n            )\n\n            # Add ground plane\n            plane_params = gymapi.PlaneParams()\n            plane_params.normal = gymapi.Vec3(0, 0, 1)\n            self.gym.add_ground(self.sim, plane_params)\n\n            # Spawn hand\n            hand_pose = gymapi.Transform()\n            hand_pose.p = gymapi.Vec3(0, 0, 0.4)\n            hand_actor = self.gym.create_actor(\n                env, self.hand_asset, hand_pose, f"hand_{i}", i, 1\n            )\n            self.hand_actors.append(hand_actor)\n\n            # Spawn object\n            object_pose = gymapi.Transform()\n            object_pose.p = gymapi.Vec3(\n                (np.random.rand() - 0.5) * 0.15,\n                (np.random.rand() - 0.5) * 0.15,\n                0.05\n            )\n            object_actor = self.gym.create_actor(\n                env, self.object_asset, object_pose, f"object_{i}", i, 2\n            )\n            self.object_actors.append(object_actor)\n\n            self.envs.append(env)\n\n    def _init_state_tensors(self):\n        """Initialize PyTorch tensors for GPU state access."""\n        # Get actor count\n        num_actors = self.gym.get_actor_count(self.sim)\n\n        # Create tensors for state access\n        self.root_tensor = torch.zeros(\n            (num_actors, 13),\n            dtype=torch.float32,\n            device=self.device\n        )\n\n        self.dof_tensor = torch.zeros(\n            (num_actors, 7),  # 7-DOF hand\n            dtype=torch.float32,\n            device=self.device\n        )\n\n        # Policy tensors\n        self.obs_tensor = torch.zeros(\n            (self.num_envs, self.num_obs),\n            dtype=torch.float32,\n            device=self.device\n        )\n\n        self.action_tensor = torch.zeros(\n            (self.num_envs, self.num_actions),\n            dtype=torch.float32,\n            device=self.device\n        )\n\n        self.rew_tensor = torch.zeros(\n            (self.num_envs,),\n            dtype=torch.float32,\n            device=self.device\n        )\n\n        self.done_tensor = torch.zeros(\n            (self.num_envs,),\n            dtype=torch.bool,\n            device=self.device\n        )\n\n    def reset(self):\n        """Reset all environments to initial state."""\n        # Randomize object positions\n        for i, (env, object_actor) in enumerate(zip(self.envs, self.object_actors)):\n            pose = gymapi.Transform()\n            pose.p = gymapi.Vec3(\n                (np.random.rand() - 0.5) * 0.15,\n                (np.random.rand() - 0.5) * 0.15,\n                0.05\n            )\n            self.gym.set_rigid_body_pose(\n                env, object_actor, 0, pose\n            )\n\n        # Reset hand positions\n        for i, (env, hand_actor) in enumerate(zip(self.envs, self.hand_actors)):\n            pose = gymapi.Transform()\n            pose.p = gymapi.Vec3(0, 0, 0.4)\n            self.gym.set_rigid_body_pose(\n                env, hand_actor, 0, pose\n            )\n\n        return self._get_obs()\n\n    def step(self, actions: torch.Tensor):\n        """Step all environments with given actions."""\n        # Apply actions\n        self._apply_actions(actions)\n\n        # Step physics\n        for _ in range(4):  # Sub-stepping\n            self.gym.simulate(self.sim)\n\n        self.gym.fetch_results(self.sim, True)\n\n        # Compute rewards and dones\n        self._compute_rewards()\n        self._compute_dones()\n\n        return self._get_obs(), self.rew_tensor, self.done_tensor, {}\n\n    def _apply_actions(self, actions: torch.Tensor):\n        """Apply joint position targets."""\n        for i, (env, hand_actor) in enumerate(zip(self.envs, self.hand_actors)):\n            joint_targets = actions[i].cpu().numpy()\n            self.gym.set_actor_dof_position_targets(\n                env, hand_actor, joint_targets\n            )\n\n    def _get_obs(self):\n        """Collect observations from all environments."""\n        # Update root tensor from simulation\n        self.gym.refresh_actor_root_state_tensor(self.sim)\n        self.gym.refresh_dof_state_tensor(self.sim)\n\n        # Extract observations from tensors\n        # Hand position (3), orientation (4), velocity (6), object position (3)\n        # Plus relative position and distance\n\n        for i in range(self.num_envs):\n            hand_idx = i * 2  # Hand is first actor in each env\n            object_idx = i * 2 + 1  # Object is second actor\n\n            hand_pos = self.root_tensor[hand_idx, :3]\n            hand_quat = self.root_tensor[hand_idx, 3:7]\n            hand_vel = self.root_tensor[hand_idx, 7:13]\n            object_pos = self.root_tensor[object_idx, :3]\n\n            # Compute relative position\n            rel_pos = object_pos - hand_pos\n            distance = torch.norm(rel_pos)\n\n            # Build observation vector\n            obs = torch.cat([\n                hand_pos, hand_quat, hand_vel,\n                object_pos, rel_pos, distance.unsqueeze(0)\n            ])\n\n            self.obs_tensor[i] = obs\n\n        return self.obs_tensor\n\n    def _compute_rewards(self):\n        """Compute reward for each environment."""\n        # Get hand and object positions\n        hand_positions = self.root_tensor[0::2, :3]\n        object_positions = self.root_tensor[1::2, :3]\n\n        # Distance reward (negative distance)\n        distances = torch.norm(hand_positions - object_positions, dim=1)\n        reward = -distances\n\n        # Grasp bonus\n        grasp_threshold = 0.02\n        grasp_bonus = torch.where(\n            distances < grasp_threshold,\n            torch.ones_like(distances) * 0.5,\n            torch.zeros_like(distances)\n        )\n        reward += grasp_bonus\n\n        self.rew_tensor = reward\n\n    def _compute_dones(self):\n        """Compute episode termination flags."""\n        # Max episode length (simulated steps)\n        # Object fallen off table\n        object_positions = self.root_tensor[1::2, 2]\n        fallen = object_positions < 0.01\n\n        self.done_tensor = fallen\n\n    def close(self):\n        """Clean up resources."""\n        self.gym.destroy_sim(self.sim)\n'})}),"\n",(0,t.jsx)(n.h4,{id:"2-reward-design-for-manipulation",children:"2. Reward Design for Manipulation"}),"\n",(0,t.jsx)(n.p,{children:"Reward functions guide policy learning toward desired behaviors. Effective reward design requires balancing multiple objectives, shaping learning trajectories, and avoiding local optima. For manipulation tasks, common objectives include task completion, effort minimization, and constraint satisfaction."}),"\n",(0,t.jsx)(n.p,{children:"Sparse rewards provide a binary signal for task success or failure. This approach is simple but can lead to slow learning due to the exploration required to discover successful behaviors. Shaped rewards provide continuous feedback, accelerating learning but risking reward hacking where the policy exploits the reward function unexpectedly."}),"\n",(0,t.jsx)(n.p,{children:"For grasping tasks, rewards typically combine distance-based attraction to objects, grasp success bonuses, and potentially penalties for excessive joint velocities or torques. The relative weighting of these components determines the learning dynamics and final policy behavior."}),"\n",(0,t.jsx)(n.h4,{id:"3-policy-training-and-evaluation",children:"3. Policy Training and Evaluation"}),"\n",(0,t.jsx)(n.p,{children:"Training loop design significantly impacts learning efficiency and final policy quality. Key considerations include learning rate scheduling, batch size selection, and evaluation frequency. Isaac Gym provides reference implementations that can serve as starting points for custom training runs."}),"\n",(0,t.jsx)(n.p,{children:"Evaluation during training identifies the best policy checkpoint for deployment. Evaluation environments should use fixed configurations to provide consistent comparisons across training iterations. Metrics including success rate, completion time, and policy smoothness guide checkpoint selection."}),"\n",(0,t.jsx)(n.h3,{id:"key-concepts-to-master-1",children:"Key Concepts to Master"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"GPU Simulation"}),": Parallel environment execution, memory management, tensor operations"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"RL Algorithms"}),": PPO objective, advantage estimation, entropy regularization"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Reward Engineering"}),": Dense vs sparse rewards, reward shaping, avoidance of reward hacking"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Policy Architecture"}),": Network design, observation encoding, action parameterization"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Training Dynamics"}),": Learning rate schedules, batch sizes, gradient clipping"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"practice-exercises-1",children:"Practice Exercises"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Exercise 1: Isaac Gym Installation and Basic Simulation"})," (3 hours)"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Install Isaac Gym package"}),"\n",(0,t.jsx)(n.li,{children:"Configure GPU physics settings"}),"\n",(0,t.jsx)(n.li,{children:"Run a basic environment with parallel simulation"}),"\n",(0,t.jsx)(n.li,{children:"Measure throughput (environment steps per second)"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Exercise 2: Grasping Environment Implementation"})," (5 hours)"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Create a grasping environment with robot hand"}),"\n",(0,t.jsx)(n.li,{children:"Implement environment reset with randomization"}),"\n",(0,t.jsx)(n.li,{children:"Define observation and action spaces"}),"\n",(0,t.jsx)(n.li,{children:"Implement basic reward function"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Exercise 3: PPO Training Setup"})," (4 hours)"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Implement PPO policy network"}),"\n",(0,t.jsx)(n.li,{children:"Set up training loop with parallel rollouts"}),"\n",(0,t.jsx)(n.li,{children:"Configure optimizer and learning rate schedule"}),"\n",(0,t.jsx)(n.li,{children:"Implement advantage estimation (GAE)"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Exercise 4: Grasp Policy Training"})," (6 hours)"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Train policy for object grasping"}),"\n",(0,t.jsx)(n.li,{children:"Monitor training progress (reward curves, success rates)"}),"\n",(0,t.jsx)(n.li,{children:"Tune hyperparameters for faster convergence"}),"\n",(0,t.jsx)(n.li,{children:"Save checkpoint at desired performance"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Exercise 5: Policy Evaluation and Export"})," (3 hours)"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Evaluate trained policy on held-out scenarios"}),"\n",(0,t.jsx)(n.li,{children:"Analyze failure modes and identify improvements"}),"\n",(0,t.jsx)(n.li,{children:"Export policy to TensorRT format"}),"\n",(0,t.jsx)(n.li,{children:"Create inference script for deployment"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"estimated-time-commitment-1",children:"Estimated Time Commitment"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Activity"}),(0,t.jsx)(n.th,{children:"Hours"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Reading and tutorials"}),(0,t.jsx)(n.td,{children:"8"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Exercise 1: Installation"}),(0,t.jsx)(n.td,{children:"3"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Exercise 2: Environment"}),(0,t.jsx)(n.td,{children:"5"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Exercise 3: PPO Setup"}),(0,t.jsx)(n.td,{children:"4"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Exercise 4: Training"}),(0,t.jsx)(n.td,{children:"6"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Exercise 5: Evaluation"}),(0,t.jsx)(n.td,{children:"3"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Troubleshooting and review"}),(0,t.jsx)(n.td,{children:"5"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Total"})}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"34 hours"})})]})]})]}),"\n",(0,t.jsx)(n.h2,{id:"week-10-reinforcement-learning-and-sim-to-real-transfer",children:"Week 10: Reinforcement Learning and Sim-to-Real Transfer"}),"\n",(0,t.jsx)(n.h3,{id:"learning-objectives-2",children:"Learning Objectives"}),"\n",(0,t.jsx)(n.p,{children:"By the end of Week 10, you will be able to:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Apply domain randomization techniques for robust policy training"}),"\n",(0,t.jsx)(n.li,{children:"Implement system identification for simulation calibration"}),"\n",(0,t.jsx)(n.li,{children:"Use domain adaptation for bridging simulation-reality gaps"}),"\n",(0,t.jsx)(n.li,{children:"Deploy trained policies on physical robot hardware"}),"\n",(0,t.jsx)(n.li,{children:"Implement safety monitoring and fallback behaviors"}),"\n",(0,t.jsx)(n.li,{children:"Evaluate transfer performance and identify improvement opportunities"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"core-topics-2",children:"Core Topics"}),"\n",(0,t.jsx)(n.h4,{id:"1-domain-randomization",children:"1. Domain Randomization"}),"\n",(0,t.jsx)(n.p,{children:"Domain randomization exposes policies to varied conditions during training, promoting robustness to distribution shift at deployment. The key insight is that if the real-world distribution is contained within the training distribution, policies generalize without explicit adaptation."}),"\n",(0,t.jsx)(n.p,{children:"Effective randomization targets parameters that affect task performance and exhibit real-world variation. For manipulation, relevant parameters include object appearance (color, texture, shape), physical properties (mass, friction, damping), and sensor characteristics (noise, exposure, lens distortion). The randomization range should span the expected real-world variation while remaining learnable."}),"\n",(0,t.jsx)(n.p,{children:"Implementation in Isaac Sim uses configuration randomization at environment reset. Each reset samples parameter values from predefined distributions, producing varied training episodes. The randomization schedule can evolve during training, starting with larger variation and narrowing as policies improve."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'# Example: Domain randomization for manipulation training\nimport numpy as np\nfrom typing import Dict, Tuple\nfrom dataclasses import dataclass\nfrom enum import Enum\n\nclass RandomizationType(Enum):\n    UNIFORM = "uniform"\n    GAUSSIAN = "gaussian"\n    DISCRETE = "discrete"\n\n\n@dataclass\nclass RandomizationConfig:\n    """Configuration for a single randomization parameter."""\n    name: str\n    base_value: float\n    randomization_type: RandomizationType\n    min_value: float\n    max_value: float\n    std: float  # For gaussian randomization\n\n\nclass DomainRandomizer:\n    """\n    Domain randomization for sim-to-real transfer.\n    Applies randomized variations to simulation parameters.\n    """\n\n    def __init__(self):\n        self.configs: Dict[str, RandomizationConfig] = {}\n        self.randomization_probability = 1.0\n\n    def add_parameter(self, config: RandomizationConfig):\n        """Add a parameter to be randomized."""\n        self.configs[config.name] = config\n\n    def randomize_all(self) -> Dict[str, float]:\n        """\n        Sample random values for all parameters.\n\n        Returns:\n            values: Dictionary of parameter names to randomized values\n        """\n        values = {}\n\n        for name, config in self.configs.items():\n            if np.random.random() < self.randomization_probability:\n                if config.randomization_type == RandomizationType.UNIFORM:\n                    value = np.random.uniform(config.min_value, config.max_value)\n                elif config.randomization_type == RandomizationType.GAUSSIAN:\n                    value = np.clip(\n                        np.random.normal(config.base_value, config.std),\n                        config.min_value,\n                        config.max_value\n                    )\n                elif config.randomization_type == RandomizationType.DISCRETE:\n                    value = np.random.choice(\n                        [config.min_value, config.base_value, config.max_value]\n                    )\n                else:\n                    value = config.base_value\n            else:\n                value = config.base_value\n\n            values[name] = value\n\n        return values\n\n\nclass IsaacSimRandomizer:\n    """\n    Domain randomizer integrated with Isaac Sim.\n    Applies randomizations to physics, appearance, and sensors.\n    """\n\n    def __init__(self, sim, randomizer: DomainRandomizer):\n        self.sim = sim\n        self.randomizer = randomizer\n        self.current_values = {}\n\n    def randomize(self):\n        """Apply randomizations to the simulation."""\n        values = self.randomizer.randomize()\n        self.current_values = values\n\n        # Apply physics randomizations\n        self._randomize_physics(values)\n\n        # Apply visual randomizations\n        self._randomize_appearance(values)\n\n        # Apply sensor randomizations\n        self._randomize_sensors(values)\n\n    def _randomize_physics(self, values: Dict[str, float]):\n        """Randomize physics parameters."""\n        # Object mass randomization\n        if "object_mass" in values:\n            self._set_object_mass(values["object_mass"])\n\n        # Friction randomization\n        if "friction" in values:\n            self._set_friction(values["friction"])\n\n        # Damping randomization\n        if "damping" in values:\n            self._set_damping(values["damping"])\n\n    def _randomize_appearance(self, values: Dict[str, float]):\n        """Randomize visual appearance of objects."""\n        # Color randomization\n        if "object_color" in values:\n            self._set_object_color(values["object_color"])\n\n        # Texture randomization\n        if "texture_scale" in values:\n            self._set_texture_scale(values["texture_scale"])\n\n        # Lighting randomization\n        if "light_intensity" in values:\n            self._set_light_intensity(values["light_intensity"])\n\n    def _randomize_sensors(self, values: Dict[str, float]):\n        """Randomize sensor characteristics."""\n        # Camera noise\n        if "camera_noise" in values:\n            self._set_camera_noise_level(values["camera_noise"])\n\n        # Exposure randomization\n        if "exposure" in values:\n            self._set_camera_exposure(values["exposure"])\n\n        # IMU noise\n        if "imu_noise" in values:\n            self._set_imu_noise_level(values["imu_noise"])\n\n    def _set_object_mass(self, mass: float):\n        """Set mass for manipulable objects."""\n        # Implementation using Isaac Gym APIs\n        pass\n\n    def _set_friction(self, friction: float):\n        """Set friction coefficient for contact surfaces."""\n        pass\n\n    def _set_damping(self, damping: float):\n        """Set joint damping parameters."""\n        pass\n\n    def _set_object_color(self, color: np.ndarray):\n        """Set RGB color for object materials."""\n        pass\n\n    def _set_texture_scale(self, scale: float):\n        """Set texture tiling scale."""\n        pass\n\n    def _set_light_intensity(self, intensity: float):\n        """Set light source intensity."""\n        pass\n\n    def _set_camera_noise_level(self, noise_std: float):\n        """Set camera noise standard deviation."""\n        pass\n\n    def _set_camera_exposure(self, exposure: float):\n        """Set camera exposure time."""\n        pass\n\n    def _set_imu_noise_level(self, noise_scale: float):\n        """Set IMU noise scale factors."""\n        pass\n\n\ndef create_manipulation_randomizer() -> IsaacSimRandomizer:\n    """Create a domain randomizer for manipulation tasks."""\n    randomizer = DomainRandomizer()\n\n    # Physics randomizations\n    randomizer.add_parameter(RandomizationConfig(\n        name="object_mass",\n        base_value=0.5,\n        randomization_type=RandomizationType.GAUSSIAN,\n        min_value=0.1,\n        max_value=2.0,\n        std=0.3\n    ))\n\n    randomizer.add_parameter(RandomizationConfig(\n        name="friction",\n        base_value=0.5,\n        randomization_type=RandomizationType.UNIFORM,\n        min_value=0.3,\n        max_value=0.8,\n        std=0.0\n    ))\n\n    randomizer.add_parameter(RandomizationConfig(\n        name="damping",\n        base_value=0.5,\n        randomization_type=RandomizationType.GAUSSIAN,\n        min_value=0.1,\n        max_value=1.0,\n        std=0.2\n    ))\n\n    # Visual randomizations\n    randomizer.add_parameter(RandomizationConfig(\n        name="object_color",\n        base_value=np.array([0.5, 0.5, 0.5]),\n        randomization_type=RandomizationType.DISCRETE,\n        min_value=0.0,\n        max_value=1.0,\n        std=0.0\n    ))\n\n    randomizer.add_parameter(RandomizationConfig(\n        name="light_intensity",\n        base_value=1000.0,\n        randomization_type=RandomizationType.GAUSSIAN,\n        min_value=500.0,\n        max_value=2000.0,\n        std=300.0\n    ))\n\n    # Sensor randomizations\n    randomizer.add_parameter(RandomizationConfig(\n        name="camera_noise",\n        base_value=0.01,\n        randomization_type=RandomizationType.UNIFORM,\n        min_value=0.0,\n        max_value=0.05,\n        std=0.0\n    ))\n\n    randomizer.add_parameter(RandomizationConfig(\n        name="exposure",\n        base_value=0.01,\n        randomization_type=RandomizationType.GAUSSIAN,\n        min_value=0.001,\n        max_value=0.033,\n        std=0.005\n    ))\n\n    return IsaacSimRandomizer(None, randomizer)\n'})}),"\n",(0,t.jsx)(n.h4,{id:"2-system-identification",children:"2. System Identification"}),"\n",(0,t.jsx)(n.p,{children:"System identification measures physical system characteristics to tune simulation parameters. This calibration reduces the sim-to-real gap by improving simulation fidelity. For humanoid robots, key identification targets include joint dynamics, sensor characteristics, and contact properties."}),"\n",(0,t.jsx)(n.p,{children:"Actuator identification measures the relationship between commanded signals and actual motion. This involves collecting data from sweep experiments and fitting parameters for motor models, gearbox dynamics, and friction. The identified parameters configure simulation joint controllers to match physical behavior."}),"\n",(0,t.jsx)(n.p,{children:"Sensor identification characterizes noise, bias, and scale factors for IMUs, encoders, and cameras. IMU calibration uses known rotation sequences to determine accelerometer and gyroscope parameters. Camera calibration uses checkerboard patterns to measure intrinsics and distortion coefficients."}),"\n",(0,t.jsx)(n.h4,{id:"3-physical-deployment",children:"3. Physical Deployment"}),"\n",(0,t.jsx)(n.p,{children:"Deploying trained policies on physical robots requires converting trained models to optimized inference engines. Isaac provides TensorRT export for GPU-optimized inference on Jetson platforms. The deployment pipeline handles sensor input processing, policy inference, and actuator command execution in real time."}),"\n",(0,t.jsx)(n.p,{children:"Safety monitoring is essential during physical deployment. Policies trained in simulation may encounter unexpected conditions that cause dangerous behavior. Safety systems should monitor joint limits, velocities, forces, and external contact. Emergency stop triggers provide fail-safe behavior when safety limits are exceeded."}),"\n",(0,t.jsx)(n.h3,{id:"key-concepts-to-master-2",children:"Key Concepts to Master"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Domain Randomization"}),": Parameter selection, randomization ranges, schedules"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"System Identification"}),": Actuator characterization, sensor calibration, parameter fitting"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"TensorRT Optimization"}),": Model export, precision selection, inference optimization"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Safety Systems"}),": Limit monitoring, emergency procedures, fallback controllers"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Deployment Pipeline"}),": Sensor interfaces, real-time constraints, latency management"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"practice-exercises-2",children:"Practice Exercises"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Exercise 1: Domain Randomization Implementation"})," (4 hours)"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Implement domain randomizer class"}),"\n",(0,t.jsx)(n.li,{children:"Add physics parameter randomization (mass, friction, damping)"}),"\n",(0,t.jsx)(n.li,{children:"Add visual randomization (colors, lighting)"}),"\n",(0,t.jsx)(n.li,{children:"Add sensor noise randomization"}),"\n",(0,t.jsx)(n.li,{children:"Integrate with training loop"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Exercise 2: System Identification Setup"})," (4 hours)"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Design system identification experiments"}),"\n",(0,t.jsx)(n.li,{children:"Collect actuator characterization data"}),"\n",(0,t.jsx)(n.li,{children:"Fit motor and friction models"}),"\n",(0,t.jsx)(n.li,{children:"Update simulation parameters"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Exercise 3: TensorRT Export"})," (3 hours)"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Export trained policy to TensorRT"}),"\n",(0,t.jsx)(n.li,{children:"Configure precision (FP16/INT8)"}),"\n",(0,t.jsx)(n.li,{children:"Benchmark inference performance"}),"\n",(0,t.jsx)(n.li,{children:"Verify correctness of exported model"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Exercise 4: Physical Deployment"})," (5 hours)"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Set up robot hardware interface"}),"\n",(0,t.jsx)(n.li,{children:"Configure sensor input pipeline"}),"\n",(0,t.jsx)(n.li,{children:"Implement safety monitoring"}),"\n",(0,t.jsx)(n.li,{children:"Deploy and test policy on physical robot"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Exercise 5: Transfer Evaluation"})," (3 hours)"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Evaluate physical performance vs simulation"}),"\n",(0,t.jsx)(n.li,{children:"Identify failure modes and gaps"}),"\n",(0,t.jsx)(n.li,{children:"Iterate on randomization and calibration"}),"\n",(0,t.jsx)(n.li,{children:"Document transfer results"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"estimated-time-commitment-2",children:"Estimated Time Commitment"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Activity"}),(0,t.jsx)(n.th,{children:"Hours"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Reading and tutorials"}),(0,t.jsx)(n.td,{children:"8"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Exercise 1: Randomization"}),(0,t.jsx)(n.td,{children:"4"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Exercise 2: System ID"}),(0,t.jsx)(n.td,{children:"4"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Exercise 3: TensorRT Export"}),(0,t.jsx)(n.td,{children:"3"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Exercise 4: Deployment"}),(0,t.jsx)(n.td,{children:"5"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Exercise 5: Evaluation"}),(0,t.jsx)(n.td,{children:"3"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Troubleshooting and review"}),(0,t.jsx)(n.td,{children:"5"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Total"})}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"32 hours"})})]})]})]}),"\n",(0,t.jsx)(n.h2,{id:"summary-and-next-steps",children:"Summary and Next Steps"}),"\n",(0,t.jsx)(n.p,{children:"Weeks 8-10 have provided comprehensive coverage of the NVIDIA Isaac ecosystem for physical AI development. Week 8 established foundations in Isaac Sim setup and perception pipeline development. Week 9 covered GPU-accelerated manipulation learning with Isaac Gym. Week 10 addressed the critical sim-to-real transfer challenge with practical deployment techniques."}),"\n",(0,t.jsx)(n.p,{children:"The skills developed across these weeks prepare you for Part 5: Humanoid Robot Design, where you will apply simulation and learning techniques to specific humanoid robot platforms. The integration of Isaac capabilities with humanoid kinematics and dynamics will enable end-to-end development from simulation to physical deployment."}),"\n",(0,t.jsx)(n.p,{children:"Moving forward, consider these areas for continued learning:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Advanced RL algorithms (offline RL, meta-learning)"}),"\n",(0,t.jsx)(n.li,{children:"Multi-task and hierarchical learning"}),"\n",(0,t.jsx)(n.li,{children:"Vision-language models for robotics"}),"\n",(0,t.jsx)(n.li,{children:"Foundation models for manipulation planning"}),"\n"]})]})}function m(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>r,x:()=>o});var s=i(6540);const t={},a=s.createContext(t);function r(e){const n=s.useContext(a);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:r(e.components),s.createElement(a.Provider,{value:n},e.children)}}}]);